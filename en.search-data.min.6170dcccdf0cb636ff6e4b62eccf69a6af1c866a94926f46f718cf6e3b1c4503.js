'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/learn-docs/docs/','title':"Docs",'content':""});index.add({'id':1,'href':'/learn-docs/docs/%E6%99%82%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/','title':"時系列分析",'content':" 時系列データとは 一定の時間間隔でとられたデータのことを時系列データという。\n記号法 時点 \\(t\\) におけるデータを \\(y_t\\) と書く。時点 \\(t\\) から \\(k\\) 時点前のデータを \\(y_{t-k}\\) と書く。特に、1時点前のデータは \\(y_{t-1}\\) と書く。\n\\(T\\) 時点までの一連の時系列データをまとめて \\(Y_T\\) のように書く。\n\\[ Y_T = \\{y\\}^T_{t=1} = \\{y_1, y_2, \\cdots ,y_T\\} \\]\nデータ生成過程(DGP : Data Generating Process) 時間経過に従って変化する確率分布のことをデータ生成過程という。データ生成過程のことを単に確率過程ということもある。時系列データはデータ生成過程の一つの実現値であると考えられる。\n各時点のデータから、そのデータを生み出すもととなったデータ生成過程を推測することを、モデリングという。\n平均 時刻 \\(t\\) におけるデータの平均を \\(\\mu_t = \\mathrm{E}[y_t]\\) と表す\n分散 時刻 \\(t\\) でにおけるデータの分散を \\(\\mathrm{Var}[y_t] = \\mathrm{E}[(y_t - \\mu_t)^2]\\) と表す。\n時系列データの構造 時系列データは以下の式のような構造をもつ\n*時系列データ = 短期の自己相関 + 周期成分 + トレンド + 外因性 + ホワイトノイズ*\n自己相関 自己相関とは、異なる時点のデータ同士の相関である。時系列データは前後のデータと相関をもつことが多い。\n例えば、お風呂の温度の変化を考えよう。前の時点でのお湯の温度が 42℃なら、次の時点の温度もだいたい 42℃程度と考えられる。一方、前の時点の温度が 30℃であったとして、次の時点の温度がいきなり 40℃まで上がることは考えにくい。すなわち、この例では、前時点の温度が高いほど次の時点での温度が高くなると考えることができる。\nこのように前後のデータ間に存在する相関関係のことを自己相関という。\n数式表現 以上で説明した自己相関を、数式を用いて定義する。\nまず、自己共分散を定義する\n  自己共分散\n\\(k\\) 時点前のデータとの共分散を \\(k\\) 次の自己共分散といい、以下の式で定義する。\n\\[ \\gamma_{kt} = \\mathrm{Cov}[y_t,y_{t-k}] = \\mathrm{E}[(y_t - \\mu_t)(y_{t-k}-\\mu_{t-k})] \\]\n    自己相関\n自己共分散を標準化したものを自己相関として定義する。\n\\(k\\) 次の自己相関は以下の式で表される。\n\\[ \\rho_{kt} = \\mathrm{Corr}[y_t,y_{t-k}] = \\cfrac{\\mathrm{Cov}[y_t,y_{t-k}]}{\\sqrt{\\mathrm{Var}[y_t]\\mathrm{Var}[y_{t-k}]}} \\]\n自己相関は標準化されているので、その絶対値 \\(|\\rho_{kt}|\\) は 1 未満になる。\n  偏自己相関 \\(k\\) 次の自己相関から、 \\(k-1\\) 次までの自己相関の影響を除いたものを、偏自己相関という。\n偏自己相関の概念について理解を深めるために、ちょっとした計算をしてみよう。\nいま、1時点前のデータとの自己相関が 0.8 の時系列データがあるとする。すなわち、時点 \\(t\\) におけるデータ \\(y_t\\) は、 1 時点前のデータ \\(y_{t-1}\\) を用いて\n\\[y_t = 0.8y_{t-1}\\]\nと表せる。\nこのとき、1時点前のデータと 2 時点前のデータとの間にも同様の相関関係があるはずなので、\n\\[ y_{t-1} = 0.8y_{t-2} \\]\nが成り立つ。\n二つの数式から合わせて \\(y_t{t-1}\\) を消去することで、 \\(y_t\\) と \\(y_{t-2}\\) との相関関係が導き出せる。\n\\[ y_{t} = 0.8 (0.8 y_{t-2}) = 0.64 y_{t-2} \\]\nこのように、2時点前との関係性については何も定義していなかったにも関わらず、1時点前との関係が 2 時点前との関係にまで波及してしまう。\nこのような波及する相関関係の影響を除いて\\(y_t\\) と \\(y_{t-k}\\) との相関関係を表すのが \\(k\\) 次の偏自己相関である。\n\\(k\\) 次の偏自己相関の定義式は以下の通り\n\\[ P_{tk} = \\cfrac{\\mathrm{Cov}[y_t-\\hat{y}_t,y_{t-k}-\\hat{y}_{t-k}]}{\\sqrt{\\mathrm{Var}[y_t-\\hat{y}_t]\\mathrm{Var}[y_{t-k}-\\hat{y}_{t-k}]}} \\]\nただし、 \\(\\hat{y}_t\\) は \\(t\\) 時点における \\(y_t\\) の推定値。\nコレログラム 何時点前との自己相関が強いか調べるために、横軸にラグを、縦軸に相関係数を取ったグラフをコレログラムという。\nPython を使ってコレログラムがどんなものか見てみよう。\nまず、疑似データを作成する。\nimport statsmodels.api as sm from statsmodels.tsa.arima_process import ArmaProcess import matplotlib.pyplot as plt # 疑似データを作成 # y[t] = 0.8 * y[t-1]のプロセスを作成 model = ArmaProcess(ar=[1, - 0.8], ma=[1]) # 200 サンプル作成 samples = model.generate_sample(200) plt.plot(samples) plt.show()   まずは自己相関のコレログラム\nsm.graphics.tsa.plot_acf(samples) plt.show()   縦軸が相関係数、横軸がデータ同士のラグの大きさである。ラグ 0 で相関係数 1 (自分自身との相関は 1)であり、ラグ 1 のとき相関係数 0.8 であることがわかる。しかし、実際には相関していないはずのラグ 2 以上のデータとも相関関係が見える。\nそれでは、本当に相関関係があるかどうか、偏自己相関のコレログラムを見てみよう。\nsm.graphics.tsa.plot_pacf(samples) plt.show()   偏自己相関のコレログラムを見れば、真実のところラグ 2 以上では相関関係がないということがわかる。\n周期成分 ホワイトノイズ 未来を予測するための情報を含まない純粋な雑音のことをホワイトノイズという。ホワイトノイズは \\(\\varepsilon_t\\) という記号で表されることが多い。\nより厳密にホワイトノイズのみたす性質を述べると、以下の 3 つである。\n 期待値が 0 分散が時間に寄らず一定 ラグが 1 以上の自己相関が 0  ホワイトノイズの確率分布として、平均 0, 分散 \\(\\sigma^2\\) の正規分布がしばしば仮定される。\nまた、 \\(\\varepsilon_t\\) がホワイトノイズに従うことを明示するために、\n\\[ \\varepsilon_t \\sim \\mathrm{W.N.}(\\sigma^2) \\]\nと書くことがある。\nホワイトノイズが実際どのような見た目をしているのかというと、\nimport numpy as np # 分散 4 のホワイトノイズを 200 サンプル作成 white_noise = np.random.normal(0, 4, size=200) plt.plot(white_noise) plt.show()   実際、このホワイトノイズの自己相関を確認しておこう。\nsm.graphics.tsa.plot_acf(white_noise) トレンド 時系列データの値が全体的に上昇したり下降したりするとき、トレンドをもつということがある。しかし、トレンドとはなんだろう。数式で表せばどうなるのか。\n以下では、それを見る。\niid 系列 互いに相関がないことを独立という。データが互いに独立で、しかも同じ確率分布から生成されている場合、これらを独立同分布(i.i.d.)なデータという。そして、i.i.d.なデータからなる時系列データを iid 系列という。\n平均 \\(\\mu\\) 分散 \\(\\sigma^2\\) の iid 系列を\n\\[ y_t \\sim \\mathrm{iid}(\\mu,\\sigma) \\]\nと表すことがある。\nランダムウォーク iid 系列の累積和からなる系列をランダムウォークという。数式で表すと、\n\\[ y_t = y_{t-1} + \\epsilon_t, \\,\\,\\,\\,\\, \\epsilon_t \\sim \\mathrm{iid}(0, \\sigma^2) \\]\n例えば、ホワイトノイズの累積和はランダムウォークの一つである。ランダムウォークはこんな見た目をしている。\nplt.plot(white_noise.cumsum()) plt.show()   ランダムウォークの見た目は、データの生成のたびに大きくかわる。\nfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(8, 5.5), sharex=True, sharey=True) for i in range(2): for j in range(2): wht_nz = np.random.normal(0, 4, size=100) ax[i,j].plot(wht_nz.cumsum()) plt.show()   ドリフト率 例えば、1時点進むごとに 2 ずつ増える時系列データを考えよう。そのようなデータは数式で\n\\[ y_t = y_{t-1} + 2 \\]\nと表せる。一般的に、\n\\[ y_t = y_{t-1} + \\delta \\]\nは時点ごとに \\(\\delta\\) ずつ増えていく。こういう時系列データを線形トレンドという。\nこれにさらにホワイトノイズ \\(\\varepsilon_t\\) をのせたものを「ドリフト率 \\(\\delta\\) の確率的トレンド」という\n\\[ y_t = y_{t-1} + \\delta + \\varepsilon_t\\]\nJulia を使って確率的トレンドをグラフにしてみよう。\nusing Plots using Distributions gr() ndist = Normal(0, 4) # ホワイトノイズの確率分布 delt = 2 # ドリフト率 # 配列を初期化 trends = zeros(200) # 初期値をセット trends[1] = 0 # データ作成 for i in 1:(length(trends)-1) trends[i+1] = trends[i] + delt + rand(ndist) end plot(trends)   外因性 外部要因による影響のこと。\n"});index.add({'id':2,'href':'/learn-docs/docs/%E6%99%82%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/state-space-model/','title':"状態空間モデル",'content':" 状態空間モデルの構成 状態空間モデルとは、直接観測されない「状態」の存在を仮定したモデルである。\n基本的なワークフローは、\n 方程式によるデータの表現 統計手法を用いた状態/パラメタの推定  の 2 部に分かれる。\n方程式によるデータ表現 状態空間モデルでは、目に見えない状態変化と状態から得られる観測結果を 2 つの異なる方程式に分けて表現する。\n 目に見えない状態の変化 : 状態方程式 状態から得られる観測結果 : 観測方程式  状態方程式 状態変化のプロセスを記述する方程式のことを状態方程式という。\n状態方程式の概念式は、\n{状態} = {前時点の状態を用いた予測値} + {過程誤差}\nで表される。\n観測方程式 状態から観測値を得るプロセスを記述する方程式を観測方程式という。\n観測方程式の概念式は、\n{観測値} = {状態} + {観測誤差}\nで表される。\n線形ガウス状態空間モデル 一次方程式でモデルが表現可能で、なおかつ誤差が正規分布に従うモデルのことを、線形ガウス状態空間モデルという。\n状態空間モデルそのものはかなり幅広い概念だが、時系列データ分析の初歩では、大抵の状態空間モデルは線形ガウス状態空間モデルを仮定している。\n線形ガウス状態空間モデルの場合は、状態の推定とモデルのパラメタの推定を分けて行うことができる。\n 状態の推定: カルマンフィルタを使う。 モデルのパラメタの推定: 最尤法を使う。  この方法は、計算コストや実装コストが低く、ストリーム処理が可能で、オンライン予測に適している。\n以下では、線形ガウス状態空間モデルの概略を述べる。\n状態方程式と観測方程式 状態方程式 時点 \\(t\\) での状態を、\\(\\bm{\\mu}_t\\) とおく。ただし、 \\(\\bm{\\mu}_t\\) は \\(D\\) 次元ベクトルとする。\nこのとき、線形ガウス状態空間モデルにおける状態方程式は、\n\\[\\begin{align} \\bm{\\mu}_t \u0026amp;= T_t\\bm{\\mu}_{t-1} + R_t\\bm{\\eta}_t, \u0026amp; \\bm{\\eta}_t \\sim \\mathcal{N}(0, Q_t) \\end{align}\\]\nとなる。\nただし、記号法は以下の通りである。\n   変数 説明     \\(T_t\\) 状態 \\(\\bm{\\mu}_{t-1}\\) から \\(\\bm{\\mu}_t\\) へ移るときの状態変化を記述する行列。   \\(\\bm{\\eta}_t\\) 状態変化に伴う過程誤差のベクトル。 平均ゼロの正規分布に従う。   \\(R_t\\) 誤差 \\(\\bm{\\eta}_t\\) が状態へおよぼす影響を記述する行列。   \\(Q_t\\) 誤差 \\(\\bm{\\eta}_t\\) が従う正規分布の共分散行列。    例えば、状態が ランダムウォーク である場合は、 \\(T_t\\) , \\(R_t\\) はともに \\(D\\) 次単位行列として、\n\\[\\begin{align} \\bm{\\mu}_t \u0026amp;= \\bm{\\mu}_{t-1} + \\bm{\\eta}_t, \u0026amp; \\bm{\\eta}_t \\sim \\mathcal{N}(0, Q_t) \\end{align}\\]\nとなる。\n(参考)三次元空間上のランダムウォーク\n  観測方程式 時点 \\(t\\) での観測値を、\\(\\bm{y}_t\\) とおく。ただし、 \\(\\bm{y}_t\\) は \\(E\\) 次元ベクトルとする。\nこのとき、線形ガウス状態空間モデルにおける観測方程式は、\n\\[\\begin{align} \\bm{y}_t \u0026amp;= Z_t\\bm{\\mu}_t + \\bm{\\varepsilon}_t, \u0026amp; \\bm{\\varepsilon}_t \\sim \\mathcal{N}(0, H_t) \\end{align}\\]\nとなる。\nただし、記号法は以下の通りである。\n   変数 説明     \\(Z_t\\) 状態 \\(\\bm{\\mu}_t\\) を観測する過程を記述する行列。   \\(\\bm{\\varepsilon}_t\\) 観測誤差のベクトル。 平均ゼロの正規分布に従う。   \\(H_t\\) 誤差 \\(\\bm{\\varepsilon}_t\\) が従う正規分布の共分散行列。    例えば、状態をそのまま観測する場合は、 \\(Z_t\\) は単位行列となる。従って観測方程式は、\n\\[\\begin{align} \\bm{y}_t \u0026amp;= \\bm{\\mu}_t + \\bm{\\varepsilon}_t, \u0026amp; \\bm{\\varepsilon}_t \\sim \\mathcal{N}(0, H_t) \\end{align}\\]\nとなる。\nフィルタリング 観測値を用いて状態の予測値を補正することをフィルタリングという。フィルタリングの流れは以下の図の通り\n  状態方程式/観測方程式によるデータ表現 線形ガウス状態空間モデルの仲間のうち、いくつかの名前のついたモデルを以下で見ていく。これらを見ることによって、状態方程式と観測方程式による表現の方法について慣れてほしい。\n線形回帰モデル 説明変数のないモデル 説明変数のない線形回帰モデルは最も簡単なモデルといえる。以下の式で表される。\n\\[\\begin{align}y_t \u0026amp;= \\alpha + v_t \u0026amp; v_t \\sim \\mathcal{N}(0, \\sigma^2) \\end{align} \\]\nこれを状態方程式と観測方程式に分割するならば、\n\\[ \\left\\{ \\begin{align} \\mu_t \u0026amp;= \\alpha \\\\\ny_t \u0026amp;= \\mu_t + v_t \\end{align} \\right. \\]\nこれは、状態は時刻に寄らず一定であり、分散一定の観測誤差だけがあるモデルとして解釈できる。\n1 次の自己回帰モデル 一次の自己回帰モデル AR(1)の式は、\n\\[ \\begin{align} y_t \u0026amp;= c + \\phi_1 y_{t-1} + w_t , \u0026amp; w_t \\sim \\mathcal{N}(0,\\sigma^2) \\end{align} \\]\nと表される。\nこれを状態方程式と観測方程式を用いて表現すると、\n\\[ \\left\\{ \\begin{align} \\mu_t \u0026amp;= c + \\phi_1 \\mu_{t-1} + w_t \\\\\\ y_t \u0026amp;= \\mu_t \\end{align} \\right. \\]\nとなる。\nAR モデルを状態空間モデルとして表すばあい、モデルがまるまる状態方程式に入る。\nAR モデルは観測誤差がないものとしてモデリングされていることに注意。\nローカルレベルモデル 過程誤差と観測誤差をともに含むモデルで、最も簡単な状態空間モデルのひとつ。以下の方程式で表される。\n\\[ \\left\\{ \\begin{align} \\mu_t \u0026amp;= \\mu_{t-1} + w_t, \u0026amp; w_t \\sim \\mathcal{N}(0, \\sigma_w^2) \\\\\ny_t \u0026amp;= \\mu_t + v_t, \u0026amp; v_t \\sim \\mathcal{N}(0, \\sigma_v^2) \\\\\n\\end{align} \\right. \\]\n状態方程式のみを見るとランダムウォーク系列である。従って、ローカルレベルモデルのことをランダムウォーク+ノイズモデルということがある。\nローカルレベルモデルの疑似データとコレログラム\n  期待値 時点 \\(t-1\\) までの状態がわかっているものとして、時点 \\(t\\) における \\(\\mu_t\\) の期待値を考える。過程誤差および観測誤差は平均 0 の正規分布に従うため、期待値をとると消える。従って、\n\\[ \\mathrm{E}[\\mu_t|\\mu_{t-1}] = \\mu_{t-1} \\]\nすなわち、状態は時刻に寄らず一定であると考えられる。つまり、もしもローカルレベルモデルを使って予測を行うのなら、予測値は前の値をそのまま返すだけのものとなる。それゆえ、このモデルそのものは予測に役立つものではない。\nARIMA モデルとの関係 ローカルレベルモデルにおいて、観測値の差分系列をとってみると、\n\\[ \\begin{align} \\Delta y_t \u0026amp;= y_t - y_{t-1} \\\\\n\u0026amp;= (\\mu_t + v_t) - (\\mu_{t-1} + v_{t-1}) \\\\\n\u0026amp;= (\\mu_{t-1} + w_t + v_t) - (\\mu_{t-1} + v_{t-1}) \\\\\n\u0026amp;= w_t + v_t - v_{t-1} \\ \\end{align} \\]\nすなわち、ローカルレベルモデルの差分系列は 1 次の移動平均モデル MA(1)で表せる。このことから、ローカルレベルモデルそれ自体は、ARIMA(0,1,1)と等価である。\nローカル線形トレンドモデル ローカルレベルモデルの状態変化に時間変化するトレンドを加えたものを、ローカル線形トレンドモデルという。状態方程式と観測方程式は以下のとおり。\n\\[ \\left\\{ \\begin{align} \\delta_t \u0026amp;= \\delta_{t-1} + \\zeta_t, \u0026amp; \\zeta_t \\sim \\mathcal{N}(0,\\sigma_{\\zeta}^2) \\\\\n\\mu_t \u0026amp;= \\mu_{t-1} + \\delta_{t-1} + w_t, \u0026amp; w_t \\sim \\mathcal{N}(0, \\sigma_w^2) \\\\\ny_t \u0026amp;= \\mu_t + v_t, \u0026amp; v_t \\sim \\mathcal{N}(0, \\sigma_v^2) \\\\\n\\end{align} \\right. \\]\n線形回帰モデルとの比較 ローカル線形トレンドモデルへの理解を深めるために、線形回帰モデルと比較する。線形回帰モデルの方程式は、\n\\[ \\begin{align} y_t \u0026amp;= \\alpha + \\beta t + v_t , \u0026amp; v_t \\sim \\mathcal{N}(0, \\sigma_v^2) \\end{align} \\]\nである。\nこれをローカル線形トレンドモデルの方程式に従って状態方程式と観測方程式の形に直すと、\n\\[ \\left\\{ \\begin{align} \\delta_t \u0026amp;= \\beta \\\\\n\\mu_t \u0026amp;= \\mu_{t-1} + \\delta_{t-1} \\\\\ny_t \u0026amp;= \\mu_t + v_t, \u0026amp; v_t \\sim \\mathcal{N}(0, \\sigma_v^2) \\\\\n\\end{align} \\right. \\]\nとなる。ただし、 \\(\\mu_0 = \\alpha\\) とする。\nローカル線形トレンドモデルと線形回帰モデルの方程式を比較することにより、ローカル線形トレンドモデルの特徴として以下の 2 点がわかる。\n トレンドの値が時間変化しうる。 過程誤差を含む。  行列による表現 ローカル線形トレンドモデルは線形ガウス状態空間モデルの一つであるから、行列を用いて以下のように線形ガウス状態空間モデルの一般形にあてはめて表現できる。\n\\[ \\left\\{ \\begin{align} \\begin{bmatrix} \\mu_t \\ \\delta_t \\ \\end{bmatrix} \u0026amp;= \\begin{bmatrix} 1 \u0026amp; 1 \\\\\\ 0 \u0026amp; 1 \\\\\n\\end{bmatrix} \\begin{bmatrix} \\mu_{t-1} \\\\\\ \\delta_{t-1} \\ \\end{bmatrix} + \\bm{\\eta}_t \\\\\ny_t \u0026amp;= \\begin{bmatrix} 1 \u0026amp; 0 \\ \\end{bmatrix} \\begin{bmatrix} \\mu_t \\\\\\ \\delta_t \\ \\end{bmatrix} + v_t \\\\\n\\end{align} \\right. \\]\nただし、 \\(\\bm{\\eta}_t \\sim \\mathcal{N}(0, Q_t)\\) , \\(v_t \\sim \\mathcal{N}(0, \\sigma_v^2)\\) である。\n\\(Q_t\\) は過程誤差の共分散行列で、\n\\[ Q_t = \\begin{bmatrix} \\sigma_{\\zeta}^2 \u0026amp; 0 \\\\\\ 0 \u0026amp; \\sigma_w^2 \\end{bmatrix} \\]\n周期変動のモデル化 ダミー変数の利用 ダミー変数を導入することにより、周期的変動をモデリングできる。たとえば、頻度 4 の季節変動があるばあい、\n\\[ \\left\\{ \\begin{align} \\gamma_{1,t} \u0026amp;= -\\gamma_{1,t-1}-\\gamma_{2,t-1}-\\gamma_{3,t-1} + \\eta_t \\,, \u0026amp; \\eta_t \\sim \\mathcal{N}(0, \\sigma_{\\eta}^2) \\\\\n\\gamma_{2,t} \u0026amp;= \\gamma_{1,t-1} \u0026amp; \\\\\n\\gamma_{3,t} \u0026amp;= \\gamma_{2,t-1} \u0026amp; \\\\\ny_t \u0026amp;= \\gamma_{1,t} + v_t \\,, \u0026amp; v_t \\sim \\mathcal{N}(0,\\sigma_v^2) \\\\\n\\end{align} \\right. \\]\nと表すことができる。\nこれがきちんと周期をモデリングできていることを確認するために、以下で \\(\\gamma_{1, t+1}\\) を計算する。(簡単のため、以下では過程誤差 \\(\\xi_t\\) を無視する)\n第一式で \\(t=t+1\\) とすると、\n\\[ \\gamma_{1, t+1} = -\\gamma_{1,t}-\\gamma_{2,t}-\\gamma_{3,t} \\]\nこれに \\(t=t\\) における結果を適用して \\(\\gamma_{1,t}\\) , \\(\\gamma_{2,t}\\) , \\(\\gamma_{3, t}\\) を消去すると、\n\\[ \\gamma_{1,t+1} = -(-\\gamma_{1,t-1}-\\gamma_{2,t-1}-\\gamma_{3,t-1})-\\gamma_{1,t-1}-\\gamma_{2,t-1} \\]\n整理して、\n\\[ \\gamma_{1, t+1} = \\gamma_{3, t-1} \\]\nしたがって、 \\(\\gamma_{1, t}\\) を \\(t=0\\) から順に並べていくと、\n\\[ \\gamma_{1, 0}, \\ -(\\gamma_{1, 0}+\\gamma_{2,0}+\\gamma_{3,0}),\\ \\gamma_{3, 0},\\ \\gamma_{2, 0}, \\ \\gamma_{1, 0},\\ \\ldots \\]\nというふうにローテーションする。従って、頻度 4 の季節変動が表現されている\n周期関数の利用 ここでは詳しく述べないが、 \\(\\sin\\) , \\(\\cos\\) などの周期関数を用いて周期成分をモデリングすることもある\n基本構造時系列モデル トレンド、周期変動、ホワイトノイズの和で表される時系列データのことを、 基本構造時系列モデル という\n基本構造時系列モデルは状態空間モデルを用いて表すことができる。\nローカル線形トレンドモデルに季節項を入れたものと考えてよい。観測方程式のみ示す。\n\\[ y_t = \\mu_t + \\gamma_t + v_t \\]\nただし、 \\(\\mu_t\\) はトレンド成分, \\(\\gamma_t\\) は季節成分を表す\n時変係数モデル ARIMAX のように、外生変数(回帰変数)を含むモデルを構築できる。これにより、異常値の補正などが可能となる。\nまた、線形回帰モデルや ARIMAX とは異なり、外生変数が時間変化するモデルを作成できる。\n例えば、ローカルレベルモデルに時変係数を入れたモデルは、\n\\[ \\left\\{ \\begin{align} \\beta_t \u0026amp;= \\beta_{t-1} + \\tau_t \\\\\n\\mu_t \u0026amp;= \\mu_{t-1} + w_t \\\\\ny_t \u0026amp;= \\mu_t + \\beta_t \\psi_t + v_t \\\\\n\\end{align} \\right. \\]\nただし、 \\(\\tau_t\\) , \\(w_t\\) , \\(v_t\\) は誤差項で、 \\(\\psi_t\\) は外生変数、 \\(\\beta_t\\) は時変係数とする。\nカルマンフィルタによる推定法 基本の流れを習得するために、ローカルレベルモデルを前提とする。\nカルマンフィルタの基本の流れ\n 1 時点先の状態の予測 観測値を用いての状態の補正  ローカルレベルモデルでは予測は前の時点と同じなので、ここでは補正の方法を扱う。補正前と補正後との関係式は、\n{補正後の状態} = {補正前の状態} + {カルマンゲイン} * {予測残差}\n補正後の状態のことを フィルタ化推定量 という。\nカルマンゲイン 補正の大きさを制御する係数のことを、カルマンゲインという。\nカルマンゲインのアイディア\n 状態の予測誤差が大きいとき: 状態の予測は外れやすいので、補正は大きくすべき。 観測誤差が大きいとき: 観測値は信頼できないので、観測値による補正量は小くするべき。  カルマンゲインの定義の概念式\n{カルマンゲイン} = {状態の予測誤差の分散} / ( {状態の予測誤差の分散} + {観測誤差の分散} )\nローカルレベルモデルでのカルマンフィルタ 記号法 以下に、ローカルレベルモデルの式を再掲する。\n\\[ \\left\\{ \\begin{align} \\mu_t \u0026amp;= \\mu_{t-1} + w_t, \u0026amp; w_t \\sim \\mathcal{N}(0, \\sigma_w^2) \\\\\ny_t \u0026amp;= \\mu_t + v_t , \u0026amp; v_t \\sim \\mathcal{N}(0, \\sigma_v^2) \\\\\n\\end{align} \\right. \\]\n以下、いくつか記号を導入する。特に明記しなければ、今後も同様の記号を用いる。\n 時点 \\(t\\) までの全ての観測値 \\(\\{y_1, \\cdots ,y_t\\}\\) を \\(Y_t\\) とする。 時点 \\(t\\) における観測値 \\(y_t\\) の予測値を \\(\\hat{y}_t\\) とする。 時点 \\(t\\) における状態 \\(\\mu_t\\) の予測値を \\(\\hat{\\mu}_t\\) とする。予測値 \\(\\hat{\\mu}_t\\) は、前時点までの観測値 \\(Y_{t-1}\\) が得られている条件のもとで、状態方程式の期待値をとることで求める。従って、\n\\[ \\hat{\\mu}_t = \\mathrm{E}[\\mu_t|Y_{t-1}] \\]\n 状態の予測値 \\(\\hat{\\mu}_t\\) を時点 \\(t\\) までの観測値 \\(Y_t\\) で補正したものを、フィルタ化推定量と呼び、\\(\\mu_{t|t}\\) であらわす。フィルタ化推定量は \\(Y_t\\) が得られた条件のもとでの \\(\\mu_t\\) の期待値である。従って、\n\\[ \\mu_{t|t} = \\mathrm{E}[\\mu_t|Y_t] \\]\n 時点 \\(t\\) における状態 \\(\\mu_{t}\\) の予測誤差の分散を \\(P_t\\) で表す。\n\\(P_t\\) は、 \\(Y_{t-1}\\) が与えられた条件のもとの \\(\\mu_t\\) の分散である。従って、\n\\[ P_t = \\mathrm{Var}[\\mu_t|Y_{t-1}] \\]\n 時点 \\(t\\) でのフィルタ化推定量 \\(\\mu_{t|t}\\) の推定誤差の分散を \\(P_{t|t}\\) で表す。\n\\(P_{t|t}\\) は、 \\(Y_t\\) が与えられた条件のもとでの状態 \\(\\mu_t\\) の分散である。従って、\n\\[ P_{t|t} = \\mathrm{Var}[\\mu_t|Y_t] \\]\n 時点 \\(t\\) での観測値 \\(y_t\\) の予測誤差の分散を \\(F_t\\) で表す。\n 時点 \\(t\\) でのカルマンゲインを \\(K_t\\) で表す。\n  カルマンフィルタの計算の流れ まず、時点 \\(t\\) における状態の予測値 \\(\\hat{\\mu}_t\\) を求める。ローカルレベルモデルでは、状態変化は起こらないので、前時点の状態をそのまま用いればよい。このとき、前時点の状態はすでに観測値によって補正されたフィルタ化推定量であることに注意する。従って、\n\\[ \\hat{\\mu}_t = \\mu_{t-1|t-1} \\]\n次に、状態の予測誤差の分散 \\(P_t\\) を求める。\n状態が \\(t\\) 時点にうつるのに伴って、過程誤差 \\(w_t\\) の大きさの分だけ状態の予測誤差が大きくなる。従って、\n\\[ P_t = P_{t-1|t-1} + \\sigma_w^2 \\]\n次に、観測値の予測値 \\(\\hat{y}_t\\) を求める。\nローカルレベルモデルでは、観測値と状態の予測値は等しいので、\n\\[ \\hat{y}_t = \\hat{\\mu}_t \\]\n観測値の予測誤差の分散 \\(F_t\\) を求める。\n観測値の予測誤差は、状態の予測誤差に観測誤差が加わるので、\n\\[ F_t = P_t + \\sigma_v^2 \\]\nカルマンゲイン \\(K_t\\) を求める。\n{カルマンゲイン} = {状態の予測誤差の分散} / ( {状態の予測誤差の分散} + {観測誤差の分散} )なので、\n\\[ K_t = \\frac{P_t}{P_t + \\sigma_v^2} = \\frac{P_t}{F_t} \\]\n従って、時刻 \\(t\\) におけるフィルタ化推定量 \\(\\mu_{t|t}\\) は、\n\\[ \\mu_{t|t} = \\hat{\\mu}_t + K_t (y_t - \\hat{y}_t) \\]\nとなる。\nまた、状態の予測誤差のフィルタ化推定量 \\(P_{t|t}\\) も以下の式で求められる。\n\\[ P_{t|t} = (1-K_t)P_t \\]\nカルマンフィルタのまとめ   状態の予測\n\\[\\begin{align} \\hat{\\mu}_t \u0026amp;= \\mu_{t-1|t-1} \\\\\nP_t \u0026amp;= P_{t-1|t-1} + \\sigma_w^2 \\\\\n\\end{align} \\]\n    観測値の予測\n\\[ \\begin{align} \\hat{y}_t \u0026amp;= \\hat{\\mu}_t \\\\\nF_t \u0026amp;= P_t + \\sigma_v^2 \\\\\n\\end{align} \\]\n    カルマンゲイン\n\\[ K_t = \\frac{P_t}{F_t} \\]\n    状態の補正\n\\[ \\begin{align} \\mu_{t|t} \u0026amp;= \\hat{\\mu}_t + K_t(y_t - \\hat{y}_t) \\\\\nP_{t|t} \u0026amp;= (1-K_t)P_t \\\\\n\\end{align} \\]\n  カルマンフィルタの問題点 状態の予測を行うためには、前期の状態が必要になる。ところが、一番最初は前期の状態が存在しないので、 \\(\\mu_0\\) と \\(P_0\\) に適当な初期値を設定しなければならない。この初期値に AIC などの情報量基準も依存してしまうので、できれば適当に決めることなしに解決する必要がある。\n散漫カルマンフィルタ カルマンフィルタの初期値の問題を解決する方法。\n\\(P_0=\\infty\\) とする。(この初期化法を 散漫初期化 という)\nこれによって、ローカルレベルモデルの場合は以下のように $\u0026mu;_0$が消える。\n\\[ \\begin{align} \\mu_{1|1} \u0026amp;= \\hat{\\mu_1} + \\cfrac{P_1}{P_1 + \\sigma_v^2}(y_1 - \\hat{y}_1) \\\\\n\u0026amp;= \\mu_{0|0} + \\cfrac{P_{0|0} + \\sigma_w^2}{P_{0|0} + \\sigma_w^2 + \\sigma_v^2}(y_1 - \\mu_{0|0}) \\\\\n\u0026amp;= \\mu_{0|0} + y_1 - \\mu_{0|0} \\\\\n\u0026amp;= y_1 \\\\\n\\end{align} \\]\nまた、 \\(P_{1|1}\\) についても、以下のように定まる。\n\\[ \\begin{align} P_{1|1} \u0026amp;= (1-K_1)P_1 \\\\\n\u0026amp;= \\left(1 - \\cfrac{P_1}{P_1 + \\sigma_v^2} \\right)P_1 \\\\\n\u0026amp;= \\left(\\cfrac{\\sigma_v^2}{P_0 + \\sigma_w^2 + \\sigma_v^2}\\right)(P_0 + \\sigma_w^2) \\\\\n\u0026amp;= \\sigma_v^2 \\\\\n\\end{align} \\]\n平滑化 与えられた観測値を用いて、そのもととなる状態よりも過去の状態を補正することを平滑化という。平滑化によって補正された状態のことを 平滑化状態 と呼ぶ。\n平滑化のアイディア  予測が外れるのは過去の状態が間違っているからだ。予測が大きく外れるほどに、補正も大きくしよう。 前時点の状態について、不確かさが大きいのなら、補正も大きくしよう。 観測値の予測誤差が大きいなら、観測値は信頼できないので補正は小さくしよう。  従って、\n{平滑化状態} = {フィルタ化推定量} + {前時点の状態の分散}/{観測値の予測誤差} * {予測残差}\n平滑化の数式 最新の時刻を \\(T\\) とする。時刻 \\(t\\) における平滑化状態とその分散をそれぞれ \\(\\tilde{\\mu}_t\\) , \\(\\tilde{P}_t\\) とおく。これらは \\(T\\) までの全ての観測値 \\(Y_T\\) が得られた条件における、状態 \\(\\mu_t\\) の条件つき期待値と分散なので、\n\\[ \\begin{align} \\tilde{\\mu}_t \u0026amp;= \\mathrm{E}[\\mu_t|Y_T] \\\\\n\\tilde{P}_t \u0026amp;= \\mathrm{Var}[\\mu_t|Y_T] \\end{align} \\]\nと書ける。\nその他はカルマンフィルタの記述時の記号法に凖じる。\n例えば、 \\(T-1\\) 時点での平滑化推定量の計算式を数式に纏めると、\n\\[ \\tilde{\\mu}_{T-1} = \\mu_{T-1|T-1} + \\frac{P_{T-1|T-1}}{F_T}(y_T - \\hat{y}_T) \\]\n状態の予測値、フィルタ化推定量、平滑化状態 似て非なるものなので、少し整理する。\n\\(Y\\) の添字に注意。\n 状態の予測値:\n\\[ \\hat{\\mu}_t = \\mathrm{E}[\\mu_t|Y_{t-1}] \\]\n フィルタ化推定量:\n\\[ \\mu_{t|t} = \\mathrm{E}[\\mu_t|Y_t] \\]\n 平滑化状態:\n\\[ \\tilde{\\mu}_t = \\mathrm{E}[\\mu_t|Y_T] \\]\n  状態平滑化漸化式 平滑化状態の計算に用いる式。上に示した計算式では、任意の時刻 \\(t\\) における平滑化推定量の導出式にはなっていない。そこで、状態平滑化漸化式 \\(r_t\\) を導入して、一般形を得る。\n\\[\\begin{align}r_{t-1} \u0026amp;= \\frac{y_t - \\hat{y}_t}{F_t} + (1 - K_t)r_t \\\\\n\\tilde{\\mu}_t \u0026amp;= \\mu_{t|t} + P_{t|t}r_t \\end{align} \\]\nただし、 \\(r_t\\) は未来から過去に向かって計算するものとし、\n\\(r_T=0\\) とする。\n平滑化状態分散 \\(\\tilde{P}_t\\) も平滑化状態と同様に状態平滑化漸化式 \\(s_t\\) を用いて求められる。\n\\[ \\begin{align} s_{t-1} \u0026amp;= \\frac{1}{F_t} + (1-K_t)^2s_t \\\\\n\\tilde{P}_t \u0026amp;= P_{t|t} - P_{t|t}^2s_t \\end{align} \\]\nただし、 \\(s_T = 0\\)\nパラメタ推定 最尤推定によってパラメタ推定を行う。ここで推定されるパラメタは過程誤差の分散と観測誤差の分散である。\n観測値の予測残差 \\(y_t - \\hat{y}_t\\) を \\(d_t\\) とおく。\n\\(d_t\\) は正規分布に従うものと仮定する。\n\\[ d_t \\sim \\mathcal{N}(0, F_t) \\]\n\\(d_t\\) の確率密度関数 \\(f(d_t)\\) は、\n\\[ f(d_t) = \\frac{1}{\\sqrt{2\\pi F_t}}\\exp\\left(-\\frac{d_t^2}{2F_t}\\right) \\]\nこのとき、尤度を \\(L\\) とすると、\n\\[ L = \\prod_{t=1}^T f(d_t) = \\prod_{t=1}^T \\frac{1}{\\sqrt{2\\pi F_t}}\\exp\\left(-\\frac{d_t^2}{2F_t}\\right) \\]\n尤度の自然対数をとって、対数尤度関数とすると、\n\\[\\log{L} = -\\frac{T}{2}\\log{2\\pi} -\\frac{1}{2}\\sum_{t=1}^T\\left\\{ \\log{F_t} + \\frac{d_t^2}{F_t} \\right\\} \\]\n実際には、定数項は無視するので、第二項を正負反転させたものを最小化するパラメタを探す。\n\\[ \\frac{1}{2}\\sum_{t=1}^T\\left\\{\\log{F_t} + \\frac{d_t^2}{F_t} \\right\\} \\]\n"});})();