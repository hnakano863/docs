'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/learn-docs/docs/','title':"Docs",'content':""});index.add({'id':1,'href':'/learn-docs/docs/survival_analysis/kaplan-meier/','title':"Kaplan-Meier Method",'content':" カプランマイヤー法 カプランマイヤー法は、生存関数を実データから推測するためのノンパラメトリックな手法のひとつ。生存時間解析では最も基本的な手法である。\n本稿では、カプランマイヤー法の説明のために、以下のデータセットを用いる。\nstart group z stop id event 0 0 1.0 0 3.0 1 True 1 0 1.0 0 5.0 2 False 2 0 1.0 1 5.0 3 True 3 0 1.0 0 6.0 4 True 4 0 1.0 0 6.0 5 False 5 6 1.0 1 8.0 5 False 6 0 0.0 1 4.0 6 False 7 0 0.0 0 5.0 7 False 8 5 0.0 1 7.0 7 True 9 0 0.0 0 8.0 8 False 10 0 0.0 0 5.0 9 False 11 5 0.0 1 9.0 9 True 12 0 0.0 0 3.0 10 False 13 3 0.0 1 10.0 10 True このデータセットは、カリフォルニア サンディエゴ大学の数学科が公開している講義資料の中に出て来た例示用のデータセットである。\nhttp://www.math.ucsd.edu/~rxu/math284/slect7.pdf から、もとのデータセットを見ることができる。\nevent 列が死亡の有無、 start は観察開始時期、 stop は観察終了時期を表している。他の列については本稿では用いない。\nそれぞれのサンプルの観察期間と、死亡の有無を確認すると、\n  半分程度が打切りであり、観測期間もサンプルによってまちまちであることがわかる。\n観測データの前処理 カプランマイヤー法の適用のために、まずは観測データを前処理する。\nまずは、サンプルの観察開始点をそろえる。\n  次に、これを生存時間順に並べ替える\n  生命表 上のグラフをみると、観察期間が 2 年までは全 14 サンプルのデータが存在しているが、その後 3 年、4年と観察期間が伸びていくほどに、サンプル数が減っていくことがわかる。\nそこで、観察期間とサンプル数、死亡数の推移をまとめた表を作成する。この表を 生命表 という。\nremoved observed censored entrance at_risk event_at 0.0 0 0 0 14 14 2.0 2 1 1 0 14 3.0 2 1 1 0 12 4.0 2 1 1 0 10 5.0 4 1 3 0 8 6.0 2 1 1 0 4 7.0 1 1 0 0 2 8.0 1 0 1 0 1 生命表のインデックスは観察期間を示す。これはグラフの x 軸に対応する。\nat_risk 列が期間中のサンプルの数、 observed は死亡数、 censored が右打切りの数である。\n例えば、2年目まではサンプルは 14 個体、そのうち、右打切りが 1 個体、死亡が 1 個体である。\n期別生存率 サンプル \\(n\\) 個体中、 \\(m\\) 個体が死んだ場合、死亡率は \\(\\frac{m}{n}\\) で計算できる。生存率は、死亡率を 1 から引けば求められるので、 \\(1 - \\frac{m}{n}\\) である。\nここで、生命表を見ればわかるように、サンプルの数は観察期間によって異なる。そこで、観察期間ごとに生存率を算出する。この生存率を、期別生存率という。\nremoved observed censored entrance at_risk death_rate \\ event_at 0.0 0 0 0 14 14 0.000000 2.0 2 1 1 0 14 0.071429 3.0 2 1 1 0 12 0.083333 4.0 2 1 1 0 10 0.100000 5.0 4 1 3 0 8 0.125000 6.0 2 1 1 0 4 0.250000 7.0 1 1 0 0 2 0.500000 8.0 1 0 1 0 1 0.000000 survival_rate event_at 0.0 1.000000 2.0 0.928571 3.0 0.916667 4.0 0.900000 5.0 0.875000 6.0 0.750000 7.0 0.500000 8.0 1.000000  累積生存率 期別生存率を互いに掛け合せたもの(累積積)を 累積生存率 という。\nカプランマイヤー法とは、この累積生存率を生存関数の推定値とする統計手法である。\nremoved observed censored entrance at_risk death_rate \\ event_at 0.0 0 0 0 14 14 0.000000 2.0 2 1 1 0 14 0.071429 3.0 2 1 1 0 12 0.083333 4.0 2 1 1 0 10 0.100000 5.0 4 1 3 0 8 0.125000 6.0 2 1 1 0 4 0.250000 7.0 1 1 0 0 2 0.500000 8.0 1 0 1 0 1 0.000000 survival_rate cumulative_survival_rate event_at 0.0 1.000000 1.000000 2.0 0.928571 0.928571 3.0 0.916667 0.851190 4.0 0.900000 0.766071 5.0 0.875000 0.670312 6.0 0.750000 0.502734 7.0 0.500000 0.251367 8.0 1.000000 0.251367  この累積生存率をグラフにすると以下のようになる。\n  Python での実装 Python の生存時間解析用ライブラリである lifelines を使えば、カプランマイヤー法がすぐに使える。\nimport matplotlib.pyplot as plt from lifelines import KaplanMeierFitter from lifelines.datasets import load_dfcv from lifelines.plotting import plot_lifetimes # データセットのダウンロード # 前の章までのデータと同じものを使っている。 dfcv_data = load_dfcv() # 観察期間の長さを計算 dfcv_data[\u0026#39;duration\u0026#39;] = dfcv_data[\u0026#39;stop\u0026#39;] - dfcv_data[\u0026#39;start\u0026#39;] # インスタンス化 kmf = KaplanMeierFitter() # データに Fit kmf.fit( dfcv_data[\u0026#39;duration\u0026#39;], event_observed=dfcv_data[\u0026#39;event\u0026#39;] ) # プロット kmf.plot() plt.show()   薄色は 95%信頼区間であり、 plot() のキーワード引数 ci_show に False を渡すことで表示を無くせる。また、系列名はデフォルトで KM_estimate となるが、これも同じくキーワード引数 label に渡す値で変えられる。他にも、 lifelines.plotting.add_at_risk_counts を使えば、サンプル数の変化を表示させることができる。\nfrom lifelines.plotting import add_at_risk_counts from matplotlib.ticker import PercentFormatter fig, ax = plt.subplots() kmf.plot( ax=ax, # 既に存在する subplot にプロットする ci_show=False, # 信頼区間を非表示 label=\u0026#34;Fantastic Result\u0026#34;, # 系列名の変更 iloc=slice(0,7), # プロットする範囲を 0~7 年に制限 linestyle=\u0026#34;--\u0026#34;, linewidth=2, color=\u0026#34;red\u0026#34;, # matplotlib の plot と同じキーワード引数が使える。 ) # サンプル数の変化を表示 add_at_risk_counts(kmf, ax=ax, labels=[\u0026#34;Fantastic Result\u0026#34;]) # 普通の matplotlib のオブジェクトとして操作できる。 ax.yaxis.set_major_formatter(PercentFormatter(xmax=1.0)) ax.set_ylim(0, None) plt.show()   "});index.add({'id':2,'href':'/learn-docs/docs/%E6%99%82%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/state-space-python/','title':"Python による状態空間モデルの実装法",'content':" Python で線形ガウス状態空間モデルを実現するには、統計分析向けライブラリの statsmodels  を用いるとよい。\nstatsmodels での線形ガウス状態空間モデルの式 statsmodels での線形ガウス状態空間モデルの式は、前の記事で導入した式と若干異なるので、注意が必要。実際に statsmodels で採用されている形式での線形ガウス状態空間モデルの式を示す。\n\\[ \\begin{align} y_t \u0026amp;= Z_t \\alpha_t + d_t + \\varepsilon_t, \u0026amp; \\varepsilon_t \\sim \\mathcal{N}(0, H_t) \\\\\n\\alpha_{t+1} \u0026amp;= T_t \\alpha_t + c_t + R_t \\eta_t, \u0026amp; \\eta_t \\sim \\mathcal{N}(0, Q_t) \\\\\n\\end{align} \\]\n第 1 式の、\\(y_t\\) についての式が観測方程式である。\nいくつかのベクトルについては、 statsmodels 固有の名前が与えられている。\n   記号 名称 説明     \\(Z_t\\) design    \\(d_t\\) obs_intercept    \\(H_t\\) obs_cov 観測誤差の共分散   \\(T_t\\) transition    \\(c_t\\) state_intercept    \\(R_t\\) selection    \\(Q_t\\) state_cov 過程誤差の共分散    ローカル線形トレンドモデルの実装 ローカル線形トレンドモデルの式を下記に再掲する。\n\\[ \\begin{align} y_t \u0026amp; = \\mu_t + \\varepsilon_t \\qquad \u0026amp; \\varepsilon_t \\sim N(0, \\sigma_\\varepsilon^2) \\\\\n\\mu_{t+1} \u0026amp; = \\mu_t + \\nu_t + \\xi_t \u0026amp; \\xi_t \\sim N(0, \\sigma_\\xi^2) \\\\\n\\nu_{t+1} \u0026amp; = \\nu_t + \\zeta_t \u0026amp; \\zeta_t \\sim N(0, \\sigma_\\zeta^2) \\\\\n\\end{align} \\]\nただし、第 1 式が観測方程式、第 3 式がトレンド変化に関する式である。\nstatsmodels では行列を用いた表現を前提とするので、上記ローカル線形トレンドモデルの式を行列を用いて書き直す。\n\\[ \\begin{align} y_t \u0026amp; = \\begin{bmatrix} 1 \u0026amp; 0 \\end{bmatrix} \\begin{bmatrix} \\mu_t \\\\\\ \\nu_t \\end{bmatrix} + \\varepsilon_t \\\\\\ \\begin{bmatrix} \\mu_{t+1} \\\\\\ \\nu_{t+1} \\end{bmatrix} \u0026amp;= \\begin{bmatrix} 1 \u0026amp; 1 \\\\\\ 0 \u0026amp; 1 \\end{bmatrix} \\begin{bmatrix} \\mu_t \\\\\\ \\nu_t \\end{bmatrix} + \\begin{bmatrix} \\xi_t \\\\\\ \\zeta_t \\end{bmatrix} \\\\\n\\end{align} \\]\nこのとき、推定すべきパラメタは、\\(\\sigma^2_\\varepsilon\\) , \\(\\sigma^2_\\xi\\) , \\(\\sigma^2_\\zeta\\) である。\nただし、 \\(\\xi_t\\) と \\(\\zeta_t\\) はひとつのベクトルにまとまっているので、 state_cov \\(Q_t\\) は \\((2 \\times 2)\\) の行列になることに注意。\n\\[ \\begin{align} H_t \u0026amp; = \\begin{bmatrix} \\sigma_\\varepsilon^2 \\end{bmatrix} \\\\\nQ_t \u0026amp; = \\begin{bmatrix} \\sigma_\\xi^2 \u0026amp; 0 \\\\\\ 0 \u0026amp; \\sigma_\\zeta^2 \\end{bmatrix} \\end{align} \\]\nモデリングフレームワーク 観測データから、カルマンフィルタと最尤法を用いて状態とパラメタを推定したい。それを実現するには、 statsmodels.tsa.statespace.MLEModel を継承したクラスを作成すればよい。ちなみに MLE は最尤推定(Maximum Likelyhood Estimator)の略。\nimport statsmodels.api as sm class LocalLinearTrend(sm.tsa.statespace.MLEModel): def __init__(self, endog): この新しく作成するモデルには、必ず以下のメソッドを定義する。\n__init__() 観測データを endog として引数にとる。\n__init__() では、モデルの方程式と状態の初期化方法を定義しなければならない。\n  モデル式の定義\nモデル式の定義方法から説明する。\nまず、状態ベクトルの次元数 k_states と、過程誤差ベクトルの次元数 k_posdef を指定する。ローカル線形トレンドモデルの場合、どちらも 2 である。\ndef __init__(self, endog): k_states = k_posdef = 2 次に、状態空間行列を定義する。状態空間行列とは、 \\(Z_t\\) や \\(d_t\\) などの statsmodels で名前のついている行列のことである。デフォルトではすべて零行列となっているので、変更しておきたい部分だけ定義すればよい。\nローカル線形トレンドモデルの場合に定義するのは、以下の表の通り。\n   行列 名前 値     \\(Z_t\\) design \\(\\begin{bmatrix} 1 \u0026amp; 0 \\ \\end{bmatrix}\\)   \\(T_t\\) transition \\(\\begin{bmatrix} 1 \u0026amp; 1 \\\\\\ 0 \u0026amp; 1 \\ \\end{bmatrix}\\)   \\(R_t\\) selection 単位行列    とくに、 selection は単位行列であることが多いのだが、うっかりで定義し忘れやすいので注意。\n# 状態空間行列は self.ssm に格納する。 # ssm は多分 state space matrix の略。 import numpy as np self.ssm[\u0026#39;design\u0026#39;] = np.array([1, 0]) self.ssm[\u0026#39;transition\u0026#39;] = np.array([[1, 1], [0, 1]]) self.ssm[\u0026#39;selection\u0026#39;] = np.eye(k_states) # 2×2 の単位行列    状態の初期化\nカルマンフィルタを実現するためには、\\(t=0\\) のときの状態ベクトルとの平均と分散を定める必要がある。\nMLEModel には、初期化を助けるための関数がそなわっているので、どの関数を選ぶかを指定するだけでよい。\n initialize_known(initial_state, initial_state_cov) : 初期値の確率分布がわかっているときに使う。 initialize_stationary : ARMA などのように、定常状態であることがわかっているときに使う。 initialize_approximate_diffuse : 散漫初期化をする。上記 2 つが適切でないときに使うと考えてよい。   散漫初期化や定常状態の場合\n# 初期化は親クラスの機能を使う super(LocalLinearTrend, self).__init__( endog, k_states=k_states, k_posdef=k_posdef, initialization=\u0026#34;approximate_diffuse\u0026#34; # initialization=\u0026#34;stationary\u0026#34; ) 初期値がわかっているとき\nsuper(LocalLinearTrend, self).__init__( endog, k_states=k_states, k_posdef=k_posdef, initialization=\u0026#34;known\u0026#34;, initial_state=np.array([0,0]) # 初期値の平均ベクトル。 initial_state_cov=np.array([[50, 0], [0, 30]]) # 初期値の共分散行列。 )  update(params) 最尤法を用いてパラメタを推定するときに、 MLEModel がパラメタの更新に用いるメソッド。新たに計算されたパラメタをそれぞれどこに代入すればいいかを設定する。\n@property def param_names(self): \u0026#34;\u0026#34;\u0026#34; 推定するパラメタの名前。 分析結果を表示するときにもこの名前が使われる。 \u0026#34;\u0026#34;\u0026#34; # ローカル線形トレンドモデルで推定するパラメタは、 # 観測誤差の分散/状態変化の誤差の分散/トレンド変化の誤差の分散の三つ return [\u0026#39;var.measurement\u0026#39;, \u0026#39;var.state\u0026#39;, \u0026#39;var.trend\u0026#39;] @property def start_params(self): \u0026#34;\u0026#34;\u0026#34; 3 つのパラメタの初期値。 わりと適当でいいけど、絶対に取り得ない値だけは避ける。 例えば、分散は 0 以下にはならないので、必ず正の値にする。 \u0026#34;\u0026#34;\u0026#34; # 今回は観測値の分散を 3 つのパラメタの初期値とする。 return [np.std(self.endog)] * 3 def update(self, params, *args, **kwargs): # まずは親クラスの結果を受け取る。 params = super(LocalLinearTrend, self).update(params, *args, **kwargs) # パラメタは array-like # 格納順序は`param-names`で決めたとおり。 # 観測誤差の分散 self.ssm[\u0026#39;obs_cov\u0026#39;,0,0] = params[0] # 過程誤差の分散 # `state_cov` は 2×2 の行列で、更新するのはその対角成分だけ。 self.ssm[\u0026#39;state_cov\u0026#39;,0,0] = params[1] self.ssm[\u0026#39;state_cov\u0026#39;,1,1] = params[2] transform/untransform パラメタの推定を行うときに、 statsmodels の最適化アルゴリズムでは、パラメタの値の範囲を制限できない。しかし、推定したいパラメタが分散のように負の値をとらないだとか、なんらかの制約条件をもつことは多い。\nこの問題の解決のために、パラメタをそのまま最適化アルゴリズムで求めるのではなく、何らかの値の変換を介することができるように設計されている。\nローカル線形トレンドモデルの場合、パラメタは全て分散なので、値は負にならない。従って、最適化アルゴリズムで求めた値(=負もとりうる)を 2 乗する。\ndef transform(self, unconstrained): \u0026#34;\u0026#34;\u0026#34; 最適化アルゴリズムの出力値を尤度評価の時に変換する。 unconstrained は np.ndarray \u0026#34;\u0026#34;\u0026#34; # ローカル線形トレンドモデルのパラメタは分散なので負にならない。 # 従って、`unconstrained` を 2 乗する return unconstrained ** 2 def untransform(self, constrained): \u0026#34;\u0026#34;\u0026#34; パラメタを最適化アルゴリズムに渡すときの変換。 constrained は np.ndarray 基本的に transform の逆の演算を行えばよい。 \u0026#34;\u0026#34;\u0026#34; return constrained ** 0.5 まとめ これまでのコードをひとまとめにする。以下がローカル線形トレンドモデルの実装になる。\nimport numpy as np import pandas as pd from scipy.stats import norm import statsmodels.api as sm class LocalLinearTrend(sm.tsa.statespace.MLEModel): \u0026#34;\u0026#34;\u0026#34;ローカル線形トレンドモデル\u0026#34;\u0026#34;\u0026#34; def __init__(self, endog): k_states = k_posdef = 2 # 状態空間の初期化 super(LocalLinearTrend, self).__init__( endog, k_states=k_states, k_posdef=k_posdef, initialization=\u0026#34;approximate_diffuse\u0026#34;, loglikelihood_burn=k_states # 尤度を求めるときに使う ) # 状態空間行列の指定 self.ssm[\u0026#39;design\u0026#39;] = np.array([1,0]) self.ssm[\u0026#39;transition\u0026#39;] = np.array([[1,1], [0,1]]) self.ssm[\u0026#39;selection\u0026#39;] = np.eye(k_states) # 過程誤差のパラメタの更新に使う # np.diag_indices は行列の対角成分を返す関数 self._state_cov_idx = (\u0026#39;state_cov\u0026#39;,) + np.diag_indices(k_posdef) @property def param_names(self): \u0026#34;\u0026#34;\u0026#34;推定するパラメタの名前\u0026#34;\u0026#34;\u0026#34; return [\u0026#39;var.measurement\u0026#39;, \u0026#39;var.level\u0026#39;, \u0026#39;var.trend\u0026#39;] @property def start_params(self): \u0026#34;\u0026#34;\u0026#34;パラメタの初期値\u0026#34;\u0026#34;\u0026#34; return [np.std(self.endog)] * 3 def transform_params(self, unconstrained): \u0026#34;\u0026#34;\u0026#34;最適化 -\u0026gt; 尤度評価の際の変換\u0026#34;\u0026#34;\u0026#34; return unconstrained ** 2 def untrandform_params(self, constrained): \u0026#34;\u0026#34;\u0026#34;尤度評価-\u0026gt;最適化の際の変換\u0026#34;\u0026#34;\u0026#34; returnconstrained ** 0.5 def update(self, params, *args, **kwargs): \u0026#34;\u0026#34;\u0026#34;パラメタの更新\u0026#34;\u0026#34;\u0026#34; params = super(LocalLinearTrend, self).update(params, *args, **kwargs) # 観測誤差の分散 self.ssm[\u0026#39;obs_cov\u0026#39;,0,0] = params[0] # 過程誤差の分散 self.ssm[self._state_cov_idx] = params[1:] サンプルデータ分析 分析の感覚をつかむために、サンプルデータセットに作成したモデルを適用する。\nサンプルには、 Rdatasets の BJsales を使う。\nbjsales = sm.datasets.get_rdataset(\u0026#34;BJsales\u0026#34;, \u0026#34;datasets\u0026#34;) # メタデータ print(bjsales.__doc__) print(\u0026#39;=\u0026#39;*80) # データシェマ bjsales.data.info() print(\u0026#39;=\u0026#39;*80) # データの先頭 5 行 bjsales.data.head()+---------+-----------------+ | BJsales | R Documentation | +---------+-----------------+ Sales Data with Leading Indicator --------------------------------- Description ~~~~~~~~~~~ The sales time series ``BJsales`` and leading indicator ``BJsales.lead`` each contain 150 observations. The objects are of class ``\u0026#34;ts\u0026#34;``. Usage ~~~~~ :: BJsales BJsales.lead Source ~~~~~~ The data are given in Box \u0026amp; Jenkins (1976). Obtained from the Time Series Data Library at http://www-personal.buseco.monash.edu.au/~hyndman/TSDL/ References ~~~~~~~~~~ G. E. P. Box and G. M. Jenkins (1976): *Time Series Analysis, Forecasting and Control*, Holden-Day, San Francisco, p. 537. P. J. Brockwell and R. A. Davis (1991): *Time Series: Theory and Methods*, Second edition, Springer Verlag, NY, pp. 414. ================================================================================ \u0026lt;class \u0026#39;pandas.core.frame.DataFrame\u0026#39;\u0026gt; RangeIndex: 150 entries, 0 to 149 Data columns (total 2 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 time 150 non-null int64 1 value 150 non-null float64 dtypes: float64(1), int64(1) memory usage: 2.5 KB ================================================================================ time value 0 1 200.1 1 2 199.5 2 3 199.4 3 4 198.9 4 5 199.0import matplotlib.pyplot as plt # 必要なのは value のみ ts = bjsales.data[\u0026#39;value\u0026#39;] # どんなデータしているか、グラフで見る。 fig = plt.figure(constrained_layout=True, figsize=(8, 5)) gs = fig.add_gridspec(2,2) ax1 = fig.add_subplot(gs[0,:]) ts.plot(ax=ax1) ax1.set_title(\u0026#39;BJ Sales Data\u0026#39;) ax2 = fig.add_subplot(gs[1,0]) sm.graphics.tsa.plot_acf(ts, ax=ax2) ax2.set_title(\u0026#34;Autocorrelation\u0026#34;) ax3 = fig.add_subplot(gs[1,1]) sm.graphics.tsa.plot_pacf(ts,ax=ax3) ax3.set_title(\u0026#34;Partial Autocorrelation\u0026#34;) plt.show()   これにモデルを適用する\nmodel = LocalLinearTrend(np.log(ts)) result = model.fit() result.summary()\u0026lt;class \u0026#39;statsmodels.iolib.summary.Summary\u0026#39;\u0026gt; \u0026#34;\u0026#34;\u0026#34; Statespace Model Results ============================================================================== Dep. Variable: value No. Observations: 150 Model: LocalLinearTrend Log Likelihood 544.866 Date: Mon, 01 Jun 2020 AIC -1083.732 Time: 17:02:47 BIC -1074.740 Sample: 0 HQIC -1080.079 - 150 Covariance Type: opg =================================================================================== coef std err z P\u0026gt;|z| [0.025 0.975] ----------------------------------------------------------------------------------- var.measurement 2.971e-11 2.98e-06 9.99e-06 1.000 -5.83e-06 5.83e-06 var.level 2.778e-05 7.44e-06 3.735 0.000 1.32e-05 4.24e-05 var.trend 2.296e-06 1.01e-06 2.264 0.024 3.09e-07 4.28e-06 =================================================================================== Ljung-Box (Q): 43.58 Jarque-Bera (JB): 0.54 Prob(Q): 0.32 Prob(JB): 0.76 Heteroskedasticity (H): 0.35 Skew: -0.00 Prob(H) (two-sided): 0.00 Kurtosis: 3.30 =================================================================================== Warnings: [1] Covariance matrix calculated using the outer product of gradients (complex-step). \u0026#34;\u0026#34;\u0026#34; 予測残差がホワイトノイズに近いほど、よいモデルといえる。\nホワイトノイズは正規分布で、自己相関がゼロで、分散が一定だった。\nLjung-Box 検定(自己相関の検定)と Jarque-Bera 検定(正規性の検定)の結果から、残差は正規分布に従い、かつ、自己相関もないといえる。\nただし、Heteroskedasticity test(分散不均一性検定)の結果を見ると、分散が一定であるとは言えなさそうである。このことから、時間変化する分散をモデルに組込めば更に精度を上げられると考えられる。\n予測残差の分布は plot_diagnostics() で見ることもできる。\nfig = plt.figure(figsize=(8, 6)) result.plot_diagnostics(fig=fig) 予測 predict = result.get_prediction() forecast = result.get_forecast(30) fig, ax = plt.subplots(figsize=(9,6)) # 観測データを黒色×マークで表す ts.plot(style=\u0026#39;.:k\u0026#39;, ax=ax, label=\u0026#39;Observations\u0026#39;) np.exp(predict.predicted_mean).plot(ax=ax, label=\u0026#39;One-step-ahead Prediction\u0026#39;) predict_ci = predict.conf_int(alpha=0.8) predict_index = np.arange(len(predict_ci)) ax.fill_between(predict_index[2:], np.exp(predict_ci).iloc[2:, 0], np.exp(predict_ci).iloc[2:, 1], alpha=0.1) np.exp(forecast.predicted_mean).plot(ax=ax, style=\u0026#39;r\u0026#39;, label=\u0026#39;Forecast\u0026#39;) forecast_ci = forecast.conf_int() forecast_index = np.arange(len(predict_ci), len(predict_ci) + len(forecast_ci)) ax.fill_between(forecast_index, np.exp(forecast_ci).iloc[:, 0], np.exp(forecast_ci).iloc[:, 1], alpha=0.1) # Cleanup the image ax.set_ylim(150, None) legend = ax.legend(loc=\u0026#39;upper left\u0026#39;, bbox_to_anchor=(0, 1));   ナイーブ予測との比較 このモデルを使うことに価値があるかどうかを考えてみる。最も単純なランダムウォークと比較する。\nmodel_rwalk = sm.tsa.UnobservedComponents(np.log(ts), level=\u0026#39;rwalk\u0026#39;) res_rwalk = model_rwalk.fit() res_rwalk.summary()\u0026lt;class \u0026#39;statsmodels.iolib.summary.Summary\u0026#39;\u0026gt; \u0026#34;\u0026#34;\u0026#34; Unobserved Components Results ============================================================================== Dep. Variable: value No. Observations: 150 Model: random walk Log Likelihood 535.509 Date: Mon, 01 Jun 2020 AIC -1069.017 Time: 17:02:50 BIC -1066.013 Sample: 0 HQIC -1067.797 - 150 Covariance Type: opg ================================================================================ coef std err z P\u0026gt;|z| [0.025 0.975] -------------------------------------------------------------------------------- sigma2.level 4.418e-05 4.31e-06 10.241 0.000 3.57e-05 5.26e-05 =================================================================================== Ljung-Box (Q): 117.00 Jarque-Bera (JB): 6.26 Prob(Q): 0.00 Prob(JB): 0.04 Heteroskedasticity (H): 0.34 Skew: 0.45 Prob(H) (two-sided): 0.00 Kurtosis: 3.44 =================================================================================== Warnings: [1] Covariance matrix calculated using the outer product of gradients (complex-step). \u0026#34;\u0026#34;\u0026#34; まず、残差に自己相関が残っており、分布も正規分布でないことがすぐにわかる。また、AIC()を比較すると\nprint(\u0026#34;LocalLinearTrend: {:.6}\u0026#34;.format(result.aic)) print(\u0026#34;RandomWalk: {:.6}\u0026#34;.format(res_rwalk.aic))LocalLinearTrend: -1083.73 RandomWalk: -1069.02 となり、ローカル線形トレンドモデルのほうが低い。すなわち、少なくともランダムウォークよりはローカル線形トレンドモデルのほうがよいモデルであるとわかる。\n"});index.add({'id':3,'href':'/learn-docs/docs/%E6%99%82%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/','title':"時系列分析",'content':" 時系列データとは 一定の時間間隔でとられたデータのことを時系列データという。\n記号法 時点 \\(t\\) におけるデータを \\(y_t\\) と書く。時点 \\(t\\) から \\(k\\) 時点前のデータを \\(y_{t-k}\\) と書く。特に、1時点前のデータは \\(y_{t-1}\\) と書く。\n\\(T\\) 時点までの一連の時系列データをまとめて \\(Y_T\\) のように書く。\n\\[ Y_T = \\{y\\}^T_{t=1} = \\{y_1, y_2, \\cdots ,y_T\\} \\]\nデータ生成過程(DGP : Data Generating Process) 時間経過に従って変化する確率分布のことをデータ生成過程という。データ生成過程のことを単に確率過程ということもある。時系列データはデータ生成過程の一つの実現値であると考えられる。\n各時点のデータから、そのデータを生み出すもととなったデータ生成過程を推測することを、モデリングという。\n平均 時刻 \\(t\\) におけるデータの平均を \\(\\mu_t = \\mathrm{E}[y_t]\\) と表す\n分散 時刻 \\(t\\) でにおけるデータの分散を \\(\\mathrm{Var}[y_t] = \\mathrm{E}[(y_t - \\mu_t)^2]\\) と表す。\n時系列データの構造 時系列データは以下の式のような構造をもつ\n*時系列データ = 短期の自己相関 + 周期成分 + トレンド + 外因性 + ホワイトノイズ*\n自己相関 自己相関とは、異なる時点のデータ同士の相関である。時系列データは前後のデータと相関をもつことが多い。\n例えば、お風呂の温度の変化を考えよう。前の時点でのお湯の温度が 42℃なら、次の時点の温度もだいたい 42℃程度と考えられる。一方、前の時点の温度が 30℃であったとして、次の時点の温度がいきなり 40℃まで上がることは考えにくい。すなわち、この例では、前時点の温度が高いほど次の時点での温度が高くなると考えることができる。\nこのように前後のデータ間に存在する相関関係のことを自己相関という。\n数式表現 以上で説明した自己相関を、数式を用いて定義する。\nまず、自己共分散を定義する\n  自己共分散\n\\(k\\) 時点前のデータとの共分散を \\(k\\) 次の自己共分散といい、以下の式で定義する。\n\\[ \\gamma_{kt} = \\mathrm{Cov}[y_t,y_{t-k}] = \\mathrm{E}[(y_t - \\mu_t)(y_{t-k}-\\mu_{t-k})] \\]\n    自己相関\n自己共分散を標準化したものを自己相関として定義する。\n\\(k\\) 次の自己相関は以下の式で表される。\n\\[ \\rho_{kt} = \\mathrm{Corr}[y_t,y_{t-k}] = \\cfrac{\\mathrm{Cov}[y_t,y_{t-k}]}{\\sqrt{\\mathrm{Var}[y_t]\\mathrm{Var}[y_{t-k}]}} \\]\n自己相関は標準化されているので、その絶対値 \\(|\\rho_{kt}|\\) は 1 未満になる。\n  偏自己相関 \\(k\\) 次の自己相関から、 \\(k-1\\) 次までの自己相関の影響を除いたものを、偏自己相関という。\n偏自己相関の概念について理解を深めるために、ちょっとした計算をしてみよう。\nいま、1時点前のデータとの自己相関が 0.8 の時系列データがあるとする。すなわち、時点 \\(t\\) におけるデータ \\(y_t\\) は、 1 時点前のデータ \\(y_{t-1}\\) を用いて\n\\[y_t = 0.8y_{t-1}\\]\nと表せる。\nこのとき、1時点前のデータと 2 時点前のデータとの間にも同様の相関関係があるはずなので、\n\\[ y_{t-1} = 0.8y_{t-2} \\]\nが成り立つ。\n二つの数式から合わせて \\(y_t{t-1}\\) を消去することで、 \\(y_t\\) と \\(y_{t-2}\\) との相関関係が導き出せる。\n\\[ y_{t} = 0.8 (0.8 y_{t-2}) = 0.64 y_{t-2} \\]\nこのように、2時点前との関係性については何も定義していなかったにも関わらず、1時点前との関係が 2 時点前との関係にまで波及してしまう。\nこのような波及する相関関係の影響を除いて\\(y_t\\) と \\(y_{t-k}\\) との相関関係を表すのが \\(k\\) 次の偏自己相関である。\n\\(k\\) 次の偏自己相関の定義式は以下の通り\n\\[ P_{tk} = \\cfrac{\\mathrm{Cov}[y_t-\\hat{y}_t,y_{t-k}-\\hat{y}_{t-k}]}{\\sqrt{\\mathrm{Var}[y_t-\\hat{y}_t]\\mathrm{Var}[y_{t-k}-\\hat{y}_{t-k}]}} \\]\nただし、 \\(\\hat{y}_t\\) は \\(t\\) 時点における \\(y_t\\) の推定値。\nコレログラム 何時点前との自己相関が強いか調べるために、横軸にラグを、縦軸に相関係数を取ったグラフをコレログラムという。\nPython を使ってコレログラムがどんなものか見てみよう。\nまず、疑似データを作成する。\nimport statsmodels.api as sm from statsmodels.tsa.arima_process import ArmaProcess import matplotlib.pyplot as plt # 疑似データを作成 # y[t] = 0.8 * y[t-1]のプロセスを作成 model = ArmaProcess(ar=[1, - 0.8], ma=[1]) # 200 サンプル作成 samples = model.generate_sample(200) plt.plot(samples) plt.show()   まずは自己相関のコレログラム\nsm.graphics.tsa.plot_acf(samples) plt.show()   縦軸が相関係数、横軸がデータ同士のラグの大きさである。ラグ 0 で相関係数 1 (自分自身との相関は 1)であり、ラグ 1 のとき相関係数 0.8 であることがわかる。しかし、実際には相関していないはずのラグ 2 以上のデータとも相関関係が見える。\nそれでは、本当に相関関係があるかどうか、偏自己相関のコレログラムを見てみよう。\nsm.graphics.tsa.plot_pacf(samples) plt.show()   偏自己相関のコレログラムを見れば、真実のところラグ 2 以上では相関関係がないということがわかる。\n周期成分 ホワイトノイズ 未来を予測するための情報を含まない純粋な雑音のことをホワイトノイズという。ホワイトノイズは \\(\\varepsilon_t\\) という記号で表されることが多い。\nより厳密にホワイトノイズのみたす性質を述べると、以下の 3 つである。\n 期待値が 0 分散が時間に寄らず一定 ラグが 1 以上の自己相関が 0  ホワイトノイズの確率分布として、平均 0, 分散 \\(\\sigma^2\\) の正規分布がしばしば仮定される。\nまた、 \\(\\varepsilon_t\\) がホワイトノイズに従うことを明示するために、\n\\[ \\varepsilon_t \\sim \\mathrm{W.N.}(\\sigma^2) \\]\nと書くことがある。\nホワイトノイズが実際どのような見た目をしているのかというと、\nimport numpy as np # 分散 4 のホワイトノイズを 200 サンプル作成 white_noise = np.random.normal(0, 4, size=200) plt.plot(white_noise) plt.show()   実際、このホワイトノイズの自己相関を確認しておこう。\nsm.graphics.tsa.plot_acf(white_noise) トレンド 時系列データの値が全体的に上昇したり下降したりするとき、トレンドをもつということがある。しかし、トレンドとはなんだろう。数式で表せばどうなるのか。\n以下では、それを見る。\niid 系列 互いに相関がないことを独立という。データが互いに独立で、しかも同じ確率分布から生成されている場合、これらを独立同分布(i.i.d.)なデータという。そして、i.i.d.なデータからなる時系列データを iid 系列という。\n平均 \\(\\mu\\) 分散 \\(\\sigma^2\\) の iid 系列を\n\\[ y_t \\sim \\mathrm{iid}(\\mu,\\sigma) \\]\nと表すことがある。\nランダムウォーク iid 系列の累積和からなる系列をランダムウォークという。数式で表すと、\n\\[ y_t = y_{t-1} + \\epsilon_t, \\,\\,\\,\\,\\, \\epsilon_t \\sim \\mathrm{iid}(0, \\sigma^2) \\]\n例えば、ホワイトノイズの累積和はランダムウォークの一つである。ランダムウォークはこんな見た目をしている。\nplt.plot(white_noise.cumsum()) plt.show()   ランダムウォークの見た目は、データの生成のたびに大きくかわる。\nfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(8, 5.5), sharex=True, sharey=True) for i in range(2): for j in range(2): wht_nz = np.random.normal(0, 4, size=100) ax[i,j].plot(wht_nz.cumsum()) plt.show()   ドリフト率 例えば、1時点進むごとに 2 ずつ増える時系列データを考えよう。そのようなデータは数式で\n\\[ y_t = y_{t-1} + 2 \\]\nと表せる。一般的に、\n\\[ y_t = y_{t-1} + \\delta \\]\nは時点ごとに \\(\\delta\\) ずつ増えていく。こういう時系列データを線形トレンドという。\nこれにさらにホワイトノイズ \\(\\varepsilon_t\\) をのせたものを「ドリフト率 \\(\\delta\\) の確率的トレンド」という\n\\[ y_t = y_{t-1} + \\delta + \\varepsilon_t\\]\nJulia を使って確率的トレンドをグラフにしてみよう。\nusing Plots using Distributions gr() ndist = Normal(0, 4) # ホワイトノイズの確率分布 delt = 2 # ドリフト率 # 配列を初期化 trends = zeros(200) # 初期値をセット trends[1] = 0 # データ作成 for i in 1:(length(trends)-1) trends[i+1] = trends[i] + delt + rand(ndist) end plot(trends)   外因性 外部要因による影響のこと。\n"});index.add({'id':4,'href':'/learn-docs/docs/%E6%99%82%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/state-space-model/','title':"状態空間モデル",'content':" 状態空間モデルの構成 状態空間モデルとは、直接観測されない「状態」の存在を仮定したモデルである。\n基本的なワークフローは、\n 方程式によるデータの表現 統計手法を用いた状態/パラメタの推定  の 2 部に分かれる。\n方程式によるデータ表現 状態空間モデルでは、目に見えない状態変化と状態から得られる観測結果を 2 つの異なる方程式に分けて表現する。\n 目に見えない状態の変化 : 状態方程式 状態から得られる観測結果 : 観測方程式  状態方程式 状態変化のプロセスを記述する方程式のことを状態方程式という。\n状態方程式の概念式は、\n{状態} = {前時点の状態を用いた予測値} + {過程誤差}\nで表される。\n観測方程式 状態から観測値を得るプロセスを記述する方程式を観測方程式という。\n観測方程式の概念式は、\n{観測値} = {状態} + {観測誤差}\nで表される。\n線形ガウス状態空間モデル 一次方程式でモデルが表現可能で、なおかつ誤差が正規分布に従うモデルのことを、線形ガウス状態空間モデルという。\n状態空間モデルそのものはかなり幅広い概念だが、時系列データ分析の初歩では、大抵の状態空間モデルは線形ガウス状態空間モデルを仮定している。\n線形ガウス状態空間モデルの場合は、状態の推定とモデルのパラメタの推定を分けて行うことができる。\n 状態の推定: カルマンフィルタを使う。 モデルのパラメタの推定: 最尤法を使う。  この方法は、計算コストや実装コストが低く、ストリーム処理が可能で、オンライン予測に適している。\n以下では、線形ガウス状態空間モデルの概略を述べる。\n状態方程式と観測方程式 状態方程式 時点 \\(t\\) での状態を、\\(\\bm{\\mu}_t\\) とおく。ただし、 \\(\\bm{\\mu}_t\\) は \\(D\\) 次元ベクトルとする。\nこのとき、線形ガウス状態空間モデルにおける状態方程式は、\n\\[\\begin{align} \\bm{\\mu}_t \u0026amp;= T_t\\bm{\\mu}_{t-1} + R_t\\bm{\\eta}_t, \u0026amp; \\bm{\\eta}_t \\sim \\mathcal{N}(0, Q_t) \\end{align}\\]\nとなる。\nただし、記号法は以下の通りである。\n   変数 説明     \\(T_t\\) 状態 \\(\\bm{\\mu}_{t-1}\\) から \\(\\bm{\\mu}_t\\) へ移るときの状態変化を記述する行列。   \\(\\bm{\\eta}_t\\) 状態変化に伴う過程誤差のベクトル。 平均ゼロの正規分布に従う。   \\(R_t\\) 誤差 \\(\\bm{\\eta}_t\\) が状態へおよぼす影響を記述する行列。   \\(Q_t\\) 誤差 \\(\\bm{\\eta}_t\\) が従う正規分布の共分散行列。    例えば、状態が ランダムウォーク である場合は、 \\(T_t\\) , \\(R_t\\) はともに \\(D\\) 次単位行列として、\n\\[\\begin{align} \\bm{\\mu}_t \u0026amp;= \\bm{\\mu}_{t-1} + \\bm{\\eta}_t, \u0026amp; \\bm{\\eta}_t \\sim \\mathcal{N}(0, Q_t) \\end{align}\\]\nとなる。\n(参考)三次元空間上のランダムウォーク\n  観測方程式 時点 \\(t\\) での観測値を、\\(\\bm{y}_t\\) とおく。ただし、 \\(\\bm{y}_t\\) は \\(E\\) 次元ベクトルとする。\nこのとき、線形ガウス状態空間モデルにおける観測方程式は、\n\\[\\begin{align} \\bm{y}_t \u0026amp;= Z_t\\bm{\\mu}_t + \\bm{\\varepsilon}_t, \u0026amp; \\bm{\\varepsilon}_t \\sim \\mathcal{N}(0, H_t) \\end{align}\\]\nとなる。\nただし、記号法は以下の通りである。\n   変数 説明     \\(Z_t\\) 状態 \\(\\bm{\\mu}_t\\) を観測する過程を記述する行列。   \\(\\bm{\\varepsilon}_t\\) 観測誤差のベクトル。 平均ゼロの正規分布に従う。   \\(H_t\\) 誤差 \\(\\bm{\\varepsilon}_t\\) が従う正規分布の共分散行列。    例えば、状態をそのまま観測する場合は、 \\(Z_t\\) は単位行列となる。従って観測方程式は、\n\\[\\begin{align} \\bm{y}_t \u0026amp;= \\bm{\\mu}_t + \\bm{\\varepsilon}_t, \u0026amp; \\bm{\\varepsilon}_t \\sim \\mathcal{N}(0, H_t) \\end{align}\\]\nとなる。\nフィルタリング 観測値を用いて状態の予測値を補正することをフィルタリングという。フィルタリングの流れは以下の図の通り\n  状態方程式/観測方程式によるデータ表現 線形ガウス状態空間モデルの仲間のうち、いくつかの名前のついたモデルを以下で見ていく。これらを見ることによって、状態方程式と観測方程式による表現の方法について慣れてほしい。\n線形回帰モデル 説明変数のないモデル 説明変数のない線形回帰モデルは最も簡単なモデルといえる。以下の式で表される。\n\\[\\begin{align}y_t \u0026amp;= \\alpha + v_t \u0026amp; v_t \\sim \\mathcal{N}(0, \\sigma^2) \\end{align} \\]\nこれを状態方程式と観測方程式に分割するならば、\n\\[ \\left\\{ \\begin{align} \\mu_t \u0026amp;= \\alpha \\\\\ny_t \u0026amp;= \\mu_t + v_t \\end{align} \\right. \\]\nこれは、状態は時刻に寄らず一定であり、分散一定の観測誤差だけがあるモデルとして解釈できる。\n1 次の自己回帰モデル 一次の自己回帰モデル AR(1)の式は、\n\\[ \\begin{align} y_t \u0026amp;= c + \\phi_1 y_{t-1} + w_t , \u0026amp; w_t \\sim \\mathcal{N}(0,\\sigma^2) \\end{align} \\]\nと表される。\nこれを状態方程式と観測方程式を用いて表現すると、\n\\[ \\left\\{ \\begin{align} \\mu_t \u0026amp;= c + \\phi_1 \\mu_{t-1} + w_t \\\\\\ y_t \u0026amp;= \\mu_t \\end{align} \\right. \\]\nとなる。\nAR モデルを状態空間モデルとして表すばあい、モデルがまるまる状態方程式に入る。\nAR モデルは観測誤差がないものとしてモデリングされていることに注意。\nローカルレベルモデル 過程誤差と観測誤差をともに含むモデルで、最も簡単な状態空間モデルのひとつ。以下の方程式で表される。\n\\[ \\left\\{ \\begin{align} \\mu_t \u0026amp;= \\mu_{t-1} + w_t, \u0026amp; w_t \\sim \\mathcal{N}(0, \\sigma_w^2) \\\\\ny_t \u0026amp;= \\mu_t + v_t, \u0026amp; v_t \\sim \\mathcal{N}(0, \\sigma_v^2) \\\\\n\\end{align} \\right. \\]\n状態方程式のみを見るとランダムウォーク系列である。従って、ローカルレベルモデルのことをランダムウォーク+ノイズモデルということがある。\nローカルレベルモデルの疑似データとコレログラム\n  期待値 時点 \\(t-1\\) までの状態がわかっているものとして、時点 \\(t\\) における \\(\\mu_t\\) の期待値を考える。過程誤差および観測誤差は平均 0 の正規分布に従うため、期待値をとると消える。従って、\n\\[ \\mathrm{E}[\\mu_t|\\mu_{t-1}] = \\mu_{t-1} \\]\nすなわち、状態は時刻に寄らず一定であると考えられる。つまり、もしもローカルレベルモデルを使って予測を行うのなら、予測値は前の値をそのまま返すだけのものとなる。それゆえ、このモデルそのものは予測に役立つものではない。\nARIMA モデルとの関係 ローカルレベルモデルにおいて、観測値の差分系列をとってみると、\n\\[ \\begin{align} \\Delta y_t \u0026amp;= y_t - y_{t-1} \\\\\n\u0026amp;= (\\mu_t + v_t) - (\\mu_{t-1} + v_{t-1}) \\\\\n\u0026amp;= (\\mu_{t-1} + w_t + v_t) - (\\mu_{t-1} + v_{t-1}) \\\\\n\u0026amp;= w_t + v_t - v_{t-1} \\ \\end{align} \\]\nすなわち、ローカルレベルモデルの差分系列は 1 次の移動平均モデル MA(1)で表せる。このことから、ローカルレベルモデルそれ自体は、ARIMA(0,1,1)と等価である。\nローカル線形トレンドモデル ローカルレベルモデルの状態変化に時間変化するトレンドを加えたものを、ローカル線形トレンドモデルという。状態方程式と観測方程式は以下のとおり。\n\\[ \\left\\{ \\begin{align} \\delta_t \u0026amp;= \\delta_{t-1} + \\zeta_t, \u0026amp; \\zeta_t \\sim \\mathcal{N}(0,\\sigma_{\\zeta}^2) \\\\\n\\mu_t \u0026amp;= \\mu_{t-1} + \\delta_{t-1} + w_t, \u0026amp; w_t \\sim \\mathcal{N}(0, \\sigma_w^2) \\\\\ny_t \u0026amp;= \\mu_t + v_t, \u0026amp; v_t \\sim \\mathcal{N}(0, \\sigma_v^2) \\\\\n\\end{align} \\right. \\]\n線形回帰モデルとの比較 ローカル線形トレンドモデルへの理解を深めるために、線形回帰モデルと比較する。線形回帰モデルの方程式は、\n\\[ \\begin{align} y_t \u0026amp;= \\alpha + \\beta t + v_t , \u0026amp; v_t \\sim \\mathcal{N}(0, \\sigma_v^2) \\end{align} \\]\nである。\nこれをローカル線形トレンドモデルの方程式に従って状態方程式と観測方程式の形に直すと、\n\\[ \\left\\{ \\begin{align} \\delta_t \u0026amp;= \\beta \\\\\n\\mu_t \u0026amp;= \\mu_{t-1} + \\delta_{t-1} \\\\\ny_t \u0026amp;= \\mu_t + v_t, \u0026amp; v_t \\sim \\mathcal{N}(0, \\sigma_v^2) \\\\\n\\end{align} \\right. \\]\nとなる。ただし、 \\(\\mu_0 = \\alpha\\) とする。\nローカル線形トレンドモデルと線形回帰モデルの方程式を比較することにより、ローカル線形トレンドモデルの特徴として以下の 2 点がわかる。\n トレンドの値が時間変化しうる。 過程誤差を含む。  行列による表現 ローカル線形トレンドモデルは線形ガウス状態空間モデルの一つであるから、行列を用いて以下のように線形ガウス状態空間モデルの一般形にあてはめて表現できる。\n\\[ \\left\\{ \\begin{align} \\begin{bmatrix} \\mu_t \\ \\delta_t \\ \\end{bmatrix} \u0026amp;= \\begin{bmatrix} 1 \u0026amp; 1 \\\\\\ 0 \u0026amp; 1 \\\\\n\\end{bmatrix} \\begin{bmatrix} \\mu_{t-1} \\\\\\ \\delta_{t-1} \\ \\end{bmatrix} + \\bm{\\eta}_t \\\\\ny_t \u0026amp;= \\begin{bmatrix} 1 \u0026amp; 0 \\ \\end{bmatrix} \\begin{bmatrix} \\mu_t \\\\\\ \\delta_t \\ \\end{bmatrix} + v_t \\\\\n\\end{align} \\right. \\]\nただし、 \\(\\bm{\\eta}_t \\sim \\mathcal{N}(0, Q_t)\\) , \\(v_t \\sim \\mathcal{N}(0, \\sigma_v^2)\\) である。\n\\(Q_t\\) は過程誤差の共分散行列で、\n\\[ Q_t = \\begin{bmatrix} \\sigma_{\\zeta}^2 \u0026amp; 0 \\\\\\ 0 \u0026amp; \\sigma_w^2 \\end{bmatrix} \\]\n周期変動のモデル化 ダミー変数の利用 ダミー変数を導入することにより、周期的変動をモデリングできる。たとえば、頻度 4 の季節変動があるばあい、\n\\[ \\left\\{ \\begin{align} \\gamma_{1,t} \u0026amp;= -\\gamma_{1,t-1}-\\gamma_{2,t-1}-\\gamma_{3,t-1} + \\eta_t \\,, \u0026amp; \\eta_t \\sim \\mathcal{N}(0, \\sigma_{\\eta}^2) \\\\\n\\gamma_{2,t} \u0026amp;= \\gamma_{1,t-1} \u0026amp; \\\\\n\\gamma_{3,t} \u0026amp;= \\gamma_{2,t-1} \u0026amp; \\\\\ny_t \u0026amp;= \\gamma_{1,t} + v_t \\,, \u0026amp; v_t \\sim \\mathcal{N}(0,\\sigma_v^2) \\\\\n\\end{align} \\right. \\]\nと表すことができる。\nこれがきちんと周期をモデリングできていることを確認するために、以下で \\(\\gamma_{1, t+1}\\) を計算する。(簡単のため、以下では過程誤差 \\(\\xi_t\\) を無視する)\n第一式で \\(t=t+1\\) とすると、\n\\[ \\gamma_{1, t+1} = -\\gamma_{1,t}-\\gamma_{2,t}-\\gamma_{3,t} \\]\nこれに \\(t=t\\) における結果を適用して \\(\\gamma_{1,t}\\) , \\(\\gamma_{2,t}\\) , \\(\\gamma_{3, t}\\) を消去すると、\n\\[ \\gamma_{1,t+1} = -(-\\gamma_{1,t-1}-\\gamma_{2,t-1}-\\gamma_{3,t-1})-\\gamma_{1,t-1}-\\gamma_{2,t-1} \\]\n整理して、\n\\[ \\gamma_{1, t+1} = \\gamma_{3, t-1} \\]\nしたがって、 \\(\\gamma_{1, t}\\) を \\(t=0\\) から順に並べていくと、\n\\[ \\gamma_{1, 0}, \\ -(\\gamma_{1, 0}+\\gamma_{2,0}+\\gamma_{3,0}),\\ \\gamma_{3, 0},\\ \\gamma_{2, 0}, \\ \\gamma_{1, 0},\\ \\ldots \\]\nというふうにローテーションする。従って、頻度 4 の季節変動が表現されている\n周期関数の利用 ここでは詳しく述べないが、 \\(\\sin\\) , \\(\\cos\\) などの周期関数を用いて周期成分をモデリングすることもある\n基本構造時系列モデル トレンド、周期変動、ホワイトノイズの和で表される時系列データのことを、 基本構造時系列モデル という\n基本構造時系列モデルは状態空間モデルを用いて表すことができる。\nローカル線形トレンドモデルに季節項を入れたものと考えてよい。観測方程式のみ示す。\n\\[ y_t = \\mu_t + \\gamma_t + v_t \\]\nただし、 \\(\\mu_t\\) はトレンド成分, \\(\\gamma_t\\) は季節成分を表す\n時変係数モデル ARIMAX のように、外生変数(回帰変数)を含むモデルを構築できる。これにより、異常値の補正などが可能となる。\nまた、線形回帰モデルや ARIMAX とは異なり、外生変数が時間変化するモデルを作成できる。\n例えば、ローカルレベルモデルに時変係数を入れたモデルは、\n\\[ \\left\\{ \\begin{align} \\beta_t \u0026amp;= \\beta_{t-1} + \\tau_t \\\\\n\\mu_t \u0026amp;= \\mu_{t-1} + w_t \\\\\ny_t \u0026amp;= \\mu_t + \\beta_t \\psi_t + v_t \\\\\n\\end{align} \\right. \\]\nただし、 \\(\\tau_t\\) , \\(w_t\\) , \\(v_t\\) は誤差項で、 \\(\\psi_t\\) は外生変数、 \\(\\beta_t\\) は時変係数とする。\nカルマンフィルタによる推定法 基本の流れを習得するために、ローカルレベルモデルを前提とする。\nカルマンフィルタの基本の流れ\n 1 時点先の状態の予測 観測値を用いての状態の補正  ローカルレベルモデルでは予測は前の時点と同じなので、ここでは補正の方法を扱う。補正前と補正後との関係式は、\n{補正後の状態} = {補正前の状態} + {カルマンゲイン} * {予測残差}\n補正後の状態のことを フィルタ化推定量 という。\nカルマンゲイン 補正の大きさを制御する係数のことを、カルマンゲインという。\nカルマンゲインのアイディア\n 状態の予測誤差が大きいとき: 状態の予測は外れやすいので、補正は大きくすべき。 観測誤差が大きいとき: 観測値は信頼できないので、観測値による補正量は小くするべき。  カルマンゲインの定義の概念式\n{カルマンゲイン} = {状態の予測誤差の分散} / ( {状態の予測誤差の分散} + {観測誤差の分散} )\nローカルレベルモデルでのカルマンフィルタ 記号法 以下に、ローカルレベルモデルの式を再掲する。\n\\[ \\left\\{ \\begin{align} \\mu_t \u0026amp;= \\mu_{t-1} + w_t, \u0026amp; w_t \\sim \\mathcal{N}(0, \\sigma_w^2) \\\\\ny_t \u0026amp;= \\mu_t + v_t , \u0026amp; v_t \\sim \\mathcal{N}(0, \\sigma_v^2) \\\\\n\\end{align} \\right. \\]\n以下、いくつか記号を導入する。特に明記しなければ、今後も同様の記号を用いる。\n 時点 \\(t\\) までの全ての観測値 \\(\\{y_1, \\cdots ,y_t\\}\\) を \\(Y_t\\) とする。 時点 \\(t\\) における観測値 \\(y_t\\) の予測値を \\(\\hat{y}_t\\) とする。 時点 \\(t\\) における状態 \\(\\mu_t\\) の予測値を \\(\\hat{\\mu}_t\\) とする。予測値 \\(\\hat{\\mu}_t\\) は、前時点までの観測値 \\(Y_{t-1}\\) が得られている条件のもとで、状態方程式の期待値をとることで求める。従って、\n\\[ \\hat{\\mu}_t = \\mathrm{E}[\\mu_t|Y_{t-1}] \\]\n 状態の予測値 \\(\\hat{\\mu}_t\\) を時点 \\(t\\) までの観測値 \\(Y_t\\) で補正したものを、フィルタ化推定量と呼び、\\(\\mu_{t|t}\\) であらわす。フィルタ化推定量は \\(Y_t\\) が得られた条件のもとでの \\(\\mu_t\\) の期待値である。従って、\n\\[ \\mu_{t|t} = \\mathrm{E}[\\mu_t|Y_t] \\]\n 時点 \\(t\\) における状態 \\(\\mu_{t}\\) の予測誤差の分散を \\(P_t\\) で表す。\n\\(P_t\\) は、 \\(Y_{t-1}\\) が与えられた条件のもとの \\(\\mu_t\\) の分散である。従って、\n\\[ P_t = \\mathrm{Var}[\\mu_t|Y_{t-1}] \\]\n 時点 \\(t\\) でのフィルタ化推定量 \\(\\mu_{t|t}\\) の推定誤差の分散を \\(P_{t|t}\\) で表す。\n\\(P_{t|t}\\) は、 \\(Y_t\\) が与えられた条件のもとでの状態 \\(\\mu_t\\) の分散である。従って、\n\\[ P_{t|t} = \\mathrm{Var}[\\mu_t|Y_t] \\]\n 時点 \\(t\\) での観測値 \\(y_t\\) の予測誤差の分散を \\(F_t\\) で表す。\n 時点 \\(t\\) でのカルマンゲインを \\(K_t\\) で表す。\n  カルマンフィルタの計算の流れ まず、時点 \\(t\\) における状態の予測値 \\(\\hat{\\mu}_t\\) を求める。ローカルレベルモデルでは、状態変化は起こらないので、前時点の状態をそのまま用いればよい。このとき、前時点の状態はすでに観測値によって補正されたフィルタ化推定量であることに注意する。従って、\n\\[ \\hat{\\mu}_t = \\mu_{t-1|t-1} \\]\n次に、状態の予測誤差の分散 \\(P_t\\) を求める。\n状態が \\(t\\) 時点にうつるのに伴って、過程誤差 \\(w_t\\) の大きさの分だけ状態の予測誤差が大きくなる。従って、\n\\[ P_t = P_{t-1|t-1} + \\sigma_w^2 \\]\n次に、観測値の予測値 \\(\\hat{y}_t\\) を求める。\nローカルレベルモデルでは、観測値と状態の予測値は等しいので、\n\\[ \\hat{y}_t = \\hat{\\mu}_t \\]\n観測値の予測誤差の分散 \\(F_t\\) を求める。\n観測値の予測誤差は、状態の予測誤差に観測誤差が加わるので、\n\\[ F_t = P_t + \\sigma_v^2 \\]\nカルマンゲイン \\(K_t\\) を求める。\n{カルマンゲイン} = {状態の予測誤差の分散} / ( {状態の予測誤差の分散} + {観測誤差の分散} )なので、\n\\[ K_t = \\frac{P_t}{P_t + \\sigma_v^2} = \\frac{P_t}{F_t} \\]\n従って、時刻 \\(t\\) におけるフィルタ化推定量 \\(\\mu_{t|t}\\) は、\n\\[ \\mu_{t|t} = \\hat{\\mu}_t + K_t (y_t - \\hat{y}_t) \\]\nとなる。\nまた、状態の予測誤差のフィルタ化推定量 \\(P_{t|t}\\) も以下の式で求められる。\n\\[ P_{t|t} = (1-K_t)P_t \\]\nカルマンフィルタのまとめ   状態の予測\n\\[\\begin{align} \\hat{\\mu}_t \u0026amp;= \\mu_{t-1|t-1} \\\\\nP_t \u0026amp;= P_{t-1|t-1} + \\sigma_w^2 \\\\\n\\end{align} \\]\n    観測値の予測\n\\[ \\begin{align} \\hat{y}_t \u0026amp;= \\hat{\\mu}_t \\\\\nF_t \u0026amp;= P_t + \\sigma_v^2 \\\\\n\\end{align} \\]\n    カルマンゲイン\n\\[ K_t = \\frac{P_t}{F_t} \\]\n    状態の補正\n\\[ \\begin{align} \\mu_{t|t} \u0026amp;= \\hat{\\mu}_t + K_t(y_t - \\hat{y}_t) \\\\\nP_{t|t} \u0026amp;= (1-K_t)P_t \\\\\n\\end{align} \\]\n  カルマンフィルタの問題点 状態の予測を行うためには、前期の状態が必要になる。ところが、一番最初は前期の状態が存在しないので、 \\(\\mu_0\\) と \\(P_0\\) に適当な初期値を設定しなければならない。この初期値に AIC などの情報量基準も依存してしまうので、できれば適当に決めることなしに解決する必要がある。\n散漫カルマンフィルタ カルマンフィルタの初期値の問題を解決する方法。\n\\(P_0=\\infty\\) とする。(この初期化法を 散漫初期化 という)\nこれによって、ローカルレベルモデルの場合は以下のように $\u0026mu;_0$が消える。\n\\[ \\begin{align} \\mu_{1|1} \u0026amp;= \\hat{\\mu_1} + \\cfrac{P_1}{P_1 + \\sigma_v^2}(y_1 - \\hat{y}_1) \\\\\n\u0026amp;= \\mu_{0|0} + \\cfrac{P_{0|0} + \\sigma_w^2}{P_{0|0} + \\sigma_w^2 + \\sigma_v^2}(y_1 - \\mu_{0|0}) \\\\\n\u0026amp;= \\mu_{0|0} + y_1 - \\mu_{0|0} \\\\\n\u0026amp;= y_1 \\\\\n\\end{align} \\]\nまた、 \\(P_{1|1}\\) についても、以下のように定まる。\n\\[ \\begin{align} P_{1|1} \u0026amp;= (1-K_1)P_1 \\\\\n\u0026amp;= \\left(1 - \\cfrac{P_1}{P_1 + \\sigma_v^2} \\right)P_1 \\\\\n\u0026amp;= \\left(\\cfrac{\\sigma_v^2}{P_0 + \\sigma_w^2 + \\sigma_v^2}\\right)(P_0 + \\sigma_w^2) \\\\\n\u0026amp;= \\sigma_v^2 \\\\\n\\end{align} \\]\n平滑化 与えられた観測値を用いて、そのもととなる状態よりも過去の状態を補正することを平滑化という。平滑化によって補正された状態のことを 平滑化状態 と呼ぶ。\n平滑化のアイディア  予測が外れるのは過去の状態が間違っているからだ。予測が大きく外れるほどに、補正も大きくしよう。 前時点の状態について、不確かさが大きいのなら、補正も大きくしよう。 観測値の予測誤差が大きいなら、観測値は信頼できないので補正は小さくしよう。  従って、\n{平滑化状態} = {フィルタ化推定量} + {前時点の状態の分散}/{観測値の予測誤差} * {予測残差}\n平滑化の数式 最新の時刻を \\(T\\) とする。時刻 \\(t\\) における平滑化状態とその分散をそれぞれ \\(\\tilde{\\mu}_t\\) , \\(\\tilde{P}_t\\) とおく。これらは \\(T\\) までの全ての観測値 \\(Y_T\\) が得られた条件における、状態 \\(\\mu_t\\) の条件つき期待値と分散なので、\n\\[ \\begin{align} \\tilde{\\mu}_t \u0026amp;= \\mathrm{E}[\\mu_t|Y_T] \\\\\n\\tilde{P}_t \u0026amp;= \\mathrm{Var}[\\mu_t|Y_T] \\end{align} \\]\nと書ける。\nその他はカルマンフィルタの記述時の記号法に凖じる。\n例えば、 \\(T-1\\) 時点での平滑化推定量の計算式を数式に纏めると、\n\\[ \\tilde{\\mu}_{T-1} = \\mu_{T-1|T-1} + \\frac{P_{T-1|T-1}}{F_T}(y_T - \\hat{y}_T) \\]\n状態の予測値、フィルタ化推定量、平滑化状態 似て非なるものなので、少し整理する。\n\\(Y\\) の添字に注意。\n 状態の予測値:\n\\[ \\hat{\\mu}_t = \\mathrm{E}[\\mu_t|Y_{t-1}] \\]\n フィルタ化推定量:\n\\[ \\mu_{t|t} = \\mathrm{E}[\\mu_t|Y_t] \\]\n 平滑化状態:\n\\[ \\tilde{\\mu}_t = \\mathrm{E}[\\mu_t|Y_T] \\]\n  状態平滑化漸化式 平滑化状態の計算に用いる式。上に示した計算式では、任意の時刻 \\(t\\) における平滑化推定量の導出式にはなっていない。そこで、状態平滑化漸化式 \\(r_t\\) を導入して、一般形を得る。\n\\[\\begin{align}r_{t-1} \u0026amp;= \\frac{y_t - \\hat{y}_t}{F_t} + (1 - K_t)r_t \\\\\n\\tilde{\\mu}_t \u0026amp;= \\mu_{t|t} + P_{t|t}r_t \\end{align} \\]\nただし、 \\(r_t\\) は未来から過去に向かって計算するものとし、\n\\(r_T=0\\) とする。\n平滑化状態分散 \\(\\tilde{P}_t\\) も平滑化状態と同様に状態平滑化漸化式 \\(s_t\\) を用いて求められる。\n\\[ \\begin{align} s_{t-1} \u0026amp;= \\frac{1}{F_t} + (1-K_t)^2s_t \\\\\n\\tilde{P}_t \u0026amp;= P_{t|t} - P_{t|t}^2s_t \\end{align} \\]\nただし、 \\(s_T = 0\\)\nパラメタ推定 最尤推定によってパラメタ推定を行う。ここで推定されるパラメタは過程誤差の分散と観測誤差の分散である。\n観測値の予測残差 \\(y_t - \\hat{y}_t\\) を \\(d_t\\) とおく。\n\\(d_t\\) は正規分布に従うものと仮定する。\n\\[ d_t \\sim \\mathcal{N}(0, F_t) \\]\n\\(d_t\\) の確率密度関数 \\(f(d_t)\\) は、\n\\[ f(d_t) = \\frac{1}{\\sqrt{2\\pi F_t}}\\exp\\left(-\\frac{d_t^2}{2F_t}\\right) \\]\nこのとき、尤度を \\(L\\) とすると、\n\\[ L = \\prod_{t=1}^T f(d_t) = \\prod_{t=1}^T \\frac{1}{\\sqrt{2\\pi F_t}}\\exp\\left(-\\frac{d_t^2}{2F_t}\\right) \\]\n尤度の自然対数をとって、対数尤度関数とすると、\n\\[\\log{L} = -\\frac{T}{2}\\log{2\\pi} -\\frac{1}{2}\\sum_{t=1}^T\\left\\{ \\log{F_t} + \\frac{d_t^2}{F_t} \\right\\} \\]\n実際には、定数項は無視するので、第二項を正負反転させたものを最小化するパラメタを探す。\n\\[ \\frac{1}{2}\\sum_{t=1}^T\\left\\{\\log{F_t} + \\frac{d_t^2}{F_t} \\right\\} \\]\n"});index.add({'id':5,'href':'/learn-docs/docs/survival_analysis/','title':"生存時間解析",'content':" 生存時間解析とは なんらかの期間の長さを解析する統計分野のこと。「生存時間」という名前がついていることから、伝統的には医学や保険数学の分野で人間が死ぬまでの時間の長さを統計的に調べるための分野であった。\nしかし、その応用範囲は単に死亡までの時間の長さだけではなく、何らかの期間の長さとみなしうるもの全てに適用できる。\n例えば、以下のような期間が生存時間解析によって調べられる。\n ある特徴の人々が死ぬまでの期間 薬の投与から治癒までの期間。 ユーザーがウェブ会員に登録してから登録を解除するまでの期間 新しい機械を稼動させてからそれが壊れるまでの期間 週刊少年ジャンプでの漫画の連載期間  生存時間解析の基本 生存時間解析に特有の基本的な考え方がいくつかある。以下、それらを解説していく。\n打切り (Censoring) 話を想像しやすいように、マウスに薬を投与してから死ぬまでの長さを調べていると考えよう。実験の常として、観察期間は限られている。従って、全てのマウスが死ぬまで実験を続けることはできない。実験終了時点で生き残っているマウスがいたとしても、実験に参加したマウス全体の寿命について、なんらかの結論を出さなければならない。\n実験観測をおこなった期間中に死亡を観測できなかったサンプルのことを、生存時間解析では 右打切り(right-censored) という。\n生存時間解析において、右打切りサンプルを無視すると、誤った結論を導いてしまうことになる。ちょっとした思考実験により、そのことを明らかにしてみよう。\nいま、あるサンプルの寿命を調べているとする。現在は調べはじめて 5 年で、そろそろ観察をやめにして結論を出したい。\n  青色が右打切りサンプルで、赤色は期間内に死亡が観測できたサンプルである。\nもしもこのサンプルで右打切りを無視して、赤色の期間を単に平均することによって平均寿命を算出しようとすれば、本来の寿命よりもかなり短い結果を導いてしまう。また、仮に、青色の右打切りサンプルを全て寿命 5 年として、先程の計算に加えて平均寿命を出そうとしても、それでもまだ本来の寿命より短い推定結果となる。そのような推定はどうかんばっても実験期間の 5 年より長くなることはない。\n実は、この観察を全部のサンプルが死ぬまで続けられたとしたら、\n  となる。\n実際、この疑似データは、平均寿命 8 年として指数分布から作成した。\n生存関数 生存時間を確率論の中で捉えるために、サンプルの寿命を確率変数として考えよう。\n\\(T\\) を生存時間を表す確率変数とする。 \\(T\\) は少なくとも \\(T \\ge 0\\) である。\nこのとき、例えば、寿命が 5 年以上である確率は、確率論の言葉で\n\\[ \\mathrm{P}(T \\ge 5) \\]\nと書き表す。\nさて、これを一般化して、 正の実数 \\(t\\) に対して、 \\(T\\) が \\(t\\) を超える確率を与える関数 \\(S\\) を考える。\n\\[ S(t) = \\mathrm{P}(T \u0026gt; t) \\]\nこの関数 \\(S\\) を、 生存関数 という。\n生存関数の性質 まず、 \\(S(t)\\) は確率であるから、\n\\[ 0 \\le S(t) \\le 1 \\]\n次に、 \\(t\\) が大きくなればなるほど、 \\(S(t)\\) は小さくなると考えられるので、 \\(S(t)\\) は単調減少関数である。\n最後に、 \\(S(t)\\) と 累積分布関数 \\(F_{T}(t)\\) との関係を考えたい。\nまず、 累積分布関数(Cumulative Distribution Function CDF)とは、寿命 \\(T\\) が \\(t\\) 以下となる確率を与える関数のことである。\n\\[ F_T(t) = \\mathrm{P}(T \\le t) \\]\n従って、生存関数 \\(S(t)\\) と累積分布関数 \\(F_{T}(t)\\) の間では、\n\\[ F_T(t) = 1 - S(t) \\]\nが成り立つ。\nちなみに、、累積分布関数 \\(F_T(t\\) を \\(t\\) について微分したものを確率密度関数(Probability Density Function PDF)といい、 \\(f_T(t)\\) で表す。\n\\[ f(t) = \\frac{\\mathrm{d}F_T}{\\mathrm{d}t} \\]\nハザード関数 いま、目の前に生きているマウスがいるとしよう。このマウスが、いまこの瞬間に死亡する確率はどのように表せるだろうか。\n現在の時刻を \\(t\\) とおくと、このマウスは時刻 \\(t\\) までは生存している。すなわち、考えようとしている確率は、 \\(T \u0026gt; t\\) という条件のもとの条件つき確率である。また、いまこの瞬間に死ぬというのは、限りなく小さい \\(\\delta t\\) に対して、 \\(T\\) が \\(t\\) と \\(t+\\delta t\\) の間にあるということである。総合すると、求める確率は、\n\\[ \\lim_{\\delta t \\to 0} \\mathrm{P}(t \\le T \\le t + \\delta t | T \u0026gt; t) \\]\nと表せる。この確率は 0 に収束する。そこで、これを \\(\\delta t\\) で割った値を考える。 これを、時刻 \\(t\\) における ハザード率 といい、 \\(h(t)\\) であらわす。\n\\[ h(t) = \\lim_{\\delta t \\to 0}\\cfrac{ \\mathrm{P}(t \\le T \\le t + \\delta t | T \u0026gt; t) }{\\delta t} \\]\n累積ハザード関数 ハザード関数 \\(h(t)\\) を t について積分したものを 累積ハザード関数 といい、 \\(H(t)\\) で表す。\n\\[ H(t) = \\int_{0}^{t} h(u)\\mathrm{d}u \\]\n生存関数とハザード関数の関係 ハザード関数の定義式を変形していく。\nまず、条件つき確率の定義から、\n\\[ \\mathrm{P}(t \\le T \\le t + \\delta t | T \u0026gt; t) = \\frac{\\mathrm{P}(t \u0026lt; T \\le t + \\delta t)}{\\mathrm{P}(T \u0026gt; t)} \\]\n分母について見ると、\n\\[ \\mathrm{P}(t \u0026lt; T \\le t + \\delta t) = \\mathrm{P}(T \u0026gt; t) - \\mathrm{P}(T \u0026gt; t + \\delta t) \\]\n生存関数 \\(S(t)\\) の定義より、 \\(\\mathrm{P}(T\u0026gt; t) = S(t)\\) だから、\n\\[ \\mathrm{P}(t \\le T \\le t + \\delta t | T \u0026gt; t) = \\frac{S(t) - S(t + \\delta t)}{S(t)} \\]\n従って、微分の定義より、\n\\[ h(t) = -\\frac{S\u0026rsquo;(t)}{S(t)} \\]\n両辺を \\(0\\) から \\(t\\) まで積分すると、\n\\[ H(t) = -\\log{S(t)} \\]\n故に、\n\\[ S(t) = \\exp{(-H(t))} \\]\n従って、生存関数、ハザード関数、累積ハザード関数とは互いに変換可能である。\n生存時間解析の関数変換マンダラ これまで出て来た関数を整理しよう。\n寿命を表す確率変数を \\(T\\) とおくとき、\n   関数名 記号 定義     生存関数 \\(S(t)\\) \\(\\mathrm{P}(T\u0026gt;t)\\)   累積分布関数 \\(F_T(t)\\) \\(\\mathrm(T \\le t)\\)   確率密度関数 \\(f_T(t)\\) \\(F\u0026rsquo;_T(t)\\)   ハザード関数 \\(h(t)\\) \\(-S\u0026rsquo;(t)/S(t)\\)   累積ハザード関数 \\(H(t)\\) \\(\\int_0^th(u)\\mathrm{d}u\\)    python の生存時間解析のライブラリ lifelines にこれらの関係を図示したものが載っている。 https://lifelines.readthedocs.io/en/latest/Survival%20Analysis%20intro.html#hazard-function\n"});index.add({'id':6,'href':'/learn-docs/docs/survival_analysis/cumulative-hazard/','title':"累積ハザード関数",'content':" 累積ハザード関数の重要性 カプランマイヤー法は生存関数の推定を行う方法であった。\nここで、生存関数 \\(S(t)\\) と累積ハザード関数 \\(H(t)\\) の関係をもう一度思い出してみよう。\n\\[ \\begin{align} H(t) \u0026amp;= -\\log{S(t)} \\\\\nS(t) \u0026amp;= \\exp{(-S(t))} \\ \\end{align} \\]\nすなわち、 \\(S(t)\\) と \\(H(t)\\) は相互に変換可能である。\nまた、これに加えて、累積ハザード関数 \\(H(t)\\) を微分すれば、ハザード関数 \\(h(t)\\) を得ることができる。\n\\[ h(t) = \\frac{\\mathrm{d}}{\\mathrm{d}t}H(t) \\]\nハザード関数 \\(h(t)\\) は時刻がちょうど \\(t\\) のときに寿命を迎える確率に結びついている。\n\\[ h(t) = \\lim_{\\delta t \\to 0}\\frac{\\mathrm{P(t \\le T \\le t + \\delta t|T \u0026gt; t)}}{\\delta t} \\]\nしかしながら、ハザード関数をデータから直接推定することは難しい。\n累積ハザード関数を推定すれば、そこから生存関数やハザード関数を得ることができる。従って、生存時間解析において、累積ハザード関数を推定することは重要なステップとなる。\n累積ハザード関数をデータから推定するためのノンパラメトリックな手法が、 Nelson-Aalen 法 である。\nNelson-Aalen 法 以下、Nelson-Aalen 法による累積ハザード関数の推定法について説明する。説明にはカプランマイヤー法のときと同じく カリフォルニア大学サンディエゴ校の例示用データセット を用いる。\nstart group z stop id event 0 0 1.0 0 3.0 1 True 1 0 1.0 0 5.0 2 False 2 0 1.0 1 5.0 3 True 3 0 1.0 0 6.0 4 True 4 0 1.0 0 6.0 5 False 5 6 1.0 1 8.0 5 False 6 0 0.0 1 4.0 6 False 7 0 0.0 0 5.0 7 False 8 5 0.0 1 7.0 7 True 9 0 0.0 0 8.0 8 False 10 0 0.0 0 5.0 9 False 11 5 0.0 1 9.0 9 True 12 0 0.0 0 3.0 10 False 13 3 0.0 1 10.0 10 True   まずは、カプランマイヤー法のときと同様に、生命表を作成する。\nremoved observed censored entrance at_risk event_at 0.0 0 0 0 14 14 2.0 2 1 1 0 14 3.0 2 1 1 0 12 4.0 2 1 1 0 10 5.0 4 1 3 0 8 6.0 2 1 1 0 4 7.0 1 1 0 0 2 8.0 1 0 1 0 1 次に、期別死亡率を計算する。\nremoved observed censored entrance at_risk death_rate event_at 0.0 0 0 0 14 14 0.000000 2.0 2 1 1 0 14 0.071429 3.0 2 1 1 0 12 0.083333 4.0 2 1 1 0 10 0.100000 5.0 4 1 3 0 8 0.125000 6.0 2 1 1 0 4 0.250000 7.0 1 1 0 0 2 0.500000 8.0 1 0 1 0 1 0.000000 最後に、期別死亡率の累積和を求める。この累積和こそが Nelson-Aalen 法による累積ハザード関数の推定量である。\nremoved observed censored entrance at_risk death_rate \\ event_at 0.0 0 0 0 14 14 0.000000 2.0 2 1 1 0 14 0.071429 3.0 2 1 1 0 12 0.083333 4.0 2 1 1 0 10 0.100000 5.0 4 1 3 0 8 0.125000 6.0 2 1 1 0 4 0.250000 7.0 1 1 0 0 2 0.500000 8.0 1 0 1 0 1 0.000000 cumulative_hazard event_at 0.0 0.000000 2.0 0.071429 3.0 0.154762 4.0 0.254762 5.0 0.379762 6.0 0.629762 7.0 1.129762 8.0 1.129762  推定した累積ハザード関数をグラフに表すと、以下のようになる。\n  Python による実装 Python のライブラリ lifelines を使って、 Nelson-Aalen 法を実現する。カプランマイヤー法と同じように実装できる。\nfrom lifelines import NelsonAalenFitter from lifelines.datasets import load_dfcv import matplotlib.pyplot as plt # データを読み込んで duration 列を作成 df = load_dfcv().eval(\u0026#39;duration = stop - start\u0026#39;) # fitter インスタンスを作成 naf = NelsonAalenFitter() # フィット naf.fit(df[\u0026#39;duration\u0026#39;], event_observed=df[\u0026#39;event\u0026#39;]) # プロット naf.plot(label=\u0026#39;cumulative_hazard\u0026#39;) # 凡例の位置調整 plt.legend(bbox_to_anchor=(0,1), loc=\u0026#34;upper left\u0026#34;) # グリッドを追加 plt.grid(True, ls=\u0026#34;--\u0026#34;, axis=\u0026#34;y\u0026#34;) plt.show()   累積ハザード関数の使い方 まず、先のセクションで推定した累積ハザード関数の縦軸の値に注目すると、その値が 1 を超えていることがわかる。すなわち、生存関数 \\(S(t)\\) やハザード関数 \\(h(t)\\) とは異なり、累積ハザード関数 \\(H(t)\\) は確率を与える関数 ではない\n従って、少くとも今の段階では、累積ハザード関数を見て何かを解釈することは難しい。むしろ、累積ハザード関数の価値は、そこからハザード関数 \\(h(t)\\) と生存関数 \\(S(t)\\) が得られるところにある。\n累積ハザード関数からハザード関数を得る 上で述べたように、累積ハザード関数 \\(H(t)\\) を微分するとハザード関数 \\(h(t)\\) が得られる。\n\\[ h(t) = \\frac{\\mathrm{d}}{\\mathrm{d}t}H(t) \\]\nこの関係を利用して、Nelson-Aalen 法による推定量から、ハザード関数を推定してみよう。\n実際には正確な微分ができるわけではないから、カーネル平滑化を行う。カーネル平滑化については本稿の主旨からずれるので解説しない。現段階では、「よしなに微分できるのだな」と思っておくとよい。\n# カーネル平滑化のためには、 `bandwidth` を指定する必要がある。 bandwidth = 3 # 先程作成した fitter インスタンスを使い回してハザード関数をプロットする naf.plot_hazard(bandwidth=bandwidth, label=\u0026#39;hazard_function\u0026#39;) # 凡例の位置調整 plt.legend(bbox_to_anchor=(0,1), loc=\u0026#34;upper left\u0026#34;) plt.show()   ハザード関数 \\(h(t)\\) は丁度 \\(t\\) 年で寿命を迎える条件つき確率の、確率密度を表している。いわば、丁度 \\(t\\) 年のときに死ぬ危険の大きさを表しているとも言える。\nこのグラフをみると、5年目くらいから死にやすくなっていることが分かる。\nハザード関数の解釈 ハザード関数の解釈に慣れるために、少し別のデータセットを用いて Nelson-Aalen 法を試してみよう。\n今回使うデータセットは、 lifelines に同梱のデータセットで、各国の首相や大統領、書記長といったリーダーの在職期間を記録したものである。\nfrom lifelines.datasets import load_dd # データのメタ情報 print(load_dd.__doc__)Classification of political regimes as democracy and dictatorship. Classification of democracies as parliamentary, semi-presidential (mixed) and presidential. Classification of dictatorships as military, civilian and royal. Coverage: 202 countries, from 1946 or year of independence to 2008.:: Size: (1808, 12) Example: ctryname Afghanistan cowcode2 700 politycode 700 un_region_name Southern Asia un_continent_name Asia ehead Mohammad Zahir Shah leaderspellreg Mohammad Zahir Shah.Afghanistan.1946.1952.Mona... democracy Non-democracy regime Monarchy start_year 1946 duration 7 observed 1 References ---------- Cheibub, José Antonio, Jennifer Gandhi, and James Raymond Vreeland. 2010. “Democracy and Dictatorship Revisited.” Public Choice, vol. 143, no. 2-1, pp. 67-101.df = load_dd() # データシェマ print(df.info()) print(\u0026#34;=\u0026#34;*80) # 頭 5 行 print(df.head()) print(\u0026#34;=\u0026#34;*80) # `democracy` 列の値を確認 print(df[\u0026#39;democracy\u0026#39;].unique())\u0026lt;class \u0026#39;pandas.core.frame.DataFrame\u0026#39;\u0026gt; RangeIndex: 1808 entries, 0 to 1807 Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 ctryname 1808 non-null object 1 cowcode2 1808 non-null int64 2 politycode 1801 non-null float64 3 un_region_name 1808 non-null object 4 un_continent_name 1808 non-null object 5 ehead 1808 non-null object 6 leaderspellreg 1808 non-null object 7 democracy 1808 non-null object 8 regime 1808 non-null object 9 start_year 1808 non-null int64 10 duration 1808 non-null int64 11 observed 1808 non-null int64 dtypes: float64(1), int64(4), object(7) memory usage: 169.6+ KB None ================================================================================ ctryname cowcode2 politycode un_region_name un_continent_name \\ 0 Afghanistan 700 700.0 Southern Asia Asia 1 Afghanistan 700 700.0 Southern Asia Asia 2 Afghanistan 700 700.0 Southern Asia Asia 3 Afghanistan 700 700.0 Southern Asia Asia 4 Afghanistan 700 700.0 Southern Asia Asia ehead leaderspellreg \\ 0 Mohammad Zahir Shah Mohammad Zahir Shah.Afghanistan.1946.1952.Mona... 1 Sardar Mohammad Daoud Sardar Mohammad Daoud.Afghanistan.1953.1962.Ci... 2 Mohammad Zahir Shah Mohammad Zahir Shah.Afghanistan.1963.1972.Mona... 3 Sardar Mohammad Daoud Sardar Mohammad Daoud.Afghanistan.1973.1977.Ci... 4 Nur Mohammad Taraki Nur Mohammad Taraki.Afghanistan.1978.1978.Civi... democracy regime start_year duration observed 0 Non-democracy Monarchy 1946 7 1 1 Non-democracy Civilian Dict 1953 10 1 2 Non-democracy Monarchy 1963 10 1 3 Non-democracy Civilian Dict 1973 5 0 4 Non-democracy Civilian Dict 1978 1 0 ================================================================================ [\u0026#39;Non-democracy\u0026#39; \u0026#39;Democracy\u0026#39;] いくつか必要な列を説明する。\nまず、 duration は在職年数を表す。次に、 observed が調査期間中に退任したか否かを表す。在職中に死亡した場合や調査終了時に在職だった場合は右打切りと考えるので、 observed は 0 となる。 democracy はカテゴリカルな値で、民主的な政体か、独裁主義などの非民主的な政体かを表している。\n今回は、 democracy 列の値を利用してデータを 2 分割することにより、政体ごとのハザード関数の差を見てみよう。\n# `democracy`列を使ってデータを 2 分割する df_democrat = df.query(\u0026#39;democracy == \u0026#34;Democracy\u0026#34;\u0026#39;) df_non_democrat = df.query(\u0026#39;democracy == \u0026#34;Non-democracy\u0026#34;\u0026#39;) # ハザード関数用のパラメタ bandwidth = 5 fig, ax = plt.subplots() # 民主主義 naf_democrat = NelsonAalenFitter() naf_democrat.fit(df_democrat[\u0026#39;duration\u0026#39;], event_observed=df_democrat[\u0026#39;observed\u0026#39;]) naf_democrat.plot_hazard(bandwidth=bandwidth, label=\u0026#34;Democracy\u0026#34;, loc=slice(0, 22)) # 非民主主義 naf_non_democrat = NelsonAalenFitter() naf_non_democrat.fit(df_non_democrat[\u0026#39;duration\u0026#39;], event_observed=df_non_democrat[\u0026#39;observed\u0026#39;]) naf_non_democrat.plot_hazard(bandwidth=bandwidth, label=\u0026#34;Non-democracy\u0026#34;, loc=slice(0,44)) plt.show()   グラフを見れば、基本的に民主政権のほうが非民主政権よりもハザード関数の値が大きいことがわかる。すなわち、民主政権のほうがリーダーの交代が起こりやすいことを示している。\nまた、民主政権のほうには在位 5 年目ほどと 12 年目ほどに 2 つ山があるのが見られる。おそらく民主政権での任期満了時期がこのあたりになるのだろう。これらの山は選挙に際して政権交代が起こりやすいことを示しているかもしれない。逆に、非民主政権は、最初の 4 年ほどは若干政権交代がおこりやすいが、そこをこえれば安定した長期政権になることが、ハザード関数の値の推移から推測できる。\n以上のように、ハザード関数はある時期のイベントの起りやすさ(=死にやすさ)を評価していると解釈してよい。\n例えば、工業製品のハザード関数などは、初期不良により最初は高く、その後初期不良のない製品ばかりになるので低下し、そして寿命を迎えるころには再度高いハザード関数の値になる。\n  このような曲線をバスタブ曲線という\n累積ハザード関数から生存関数を得る 累積ハザード関数 \\(H(t)\\) と生存関数 \\(S(t)\\) の間には、\n\\[ S(t) = \\exp (-H(t)) \\]\nという関係が成り立つ。従って、累積ハザード関数から生存関数を計算することができる。\nNelson-Aalen 法によって推定した累積ハザード関数から、この関係式を使って生存関数を推定する方法を、 Fleming-Harrington 法 という。\nlifelines では、 BreslowFlemingHarringtonFitter というクラスが、Fleming-Harrington 法を実装している。\n再び、カリフォルニア大学サンディエゴ校の例示用データセットを用いて、カプランマイヤー法と比較してみよう。\nfrom lifelines import KaplanMeierFitter, BreslowFlemingHarringtonFitter from matplotlib.ticker import PercentFormatter # データをロードして`duration`列を作成 df = load_dfcv().eval(\u0026#39;duration = stop - start\u0026#39;) # 1 行 2 列でサブプロットを作成 fig, ax = plt.subplots(ncols=2, sharex=True, figsize=(13, 4.8)) # カラーマップを準備 cmap = plt.get_cmap(\u0026#39;tab10\u0026#39;) # カプランマイヤー法と Fleming-Harrington 法のプロットを作成 for i, fitter in enumerate([KaplanMeierFitter(), BreslowFlemingHarringtonFitter()]): fitter.fit(df[\u0026#39;duration\u0026#39;], event_observed=df[\u0026#39;event\u0026#39;]) # これは`BreslowFlemingHarringtonFitter.plot()`のバグに対するパッチ if not hasattr(fitter, \u0026#34;confidence_interval_survival_function_\u0026#34;): fitter.confidence_interval_survival_function_ = fitter.confidence_interval_ fitter.plot(ax=ax[i], color=cmap(i)) # プロットの体裁を整える ax[i].yaxis.set_major_formatter(PercentFormatter(xmax=1)) ax[i].yaxis.grid(True, ls=\u0026#34;--\u0026#34;) ax[i].set_title(f\u0026#34;{fitter.__class__.__name__} Estimate\u0026#34;) plt.show()   左右の違いを比べると殆ど変らないことがわかる。では、わざわざ Fleming-Harrington 法を使う理由はどこにあるのだろうか。\n実は、サンプルが少ない場合、Fleming-Harrington 法のほうが極端な値が出にくくなるというメリットがある。これは、カプランマイヤー法が累積積を用いるので異常な値の影響を受けやすいのに対し、Fleming-Harrington 法は累積和を用いるため異常値の影響を抑えられるからである。\n"});})();